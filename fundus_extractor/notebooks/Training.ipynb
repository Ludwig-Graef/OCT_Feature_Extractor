{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Tuple, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torchvision.datasets import DatasetFolder, ImageFolder\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA as Sklearn_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from fundus_extractor.utils.general import imshow, normalize_image\n",
    "from fundus_extractor.utils.datasets import Fundus_Left_Right_Combined_Dataset\n",
    "from fundus_extractor.models import pretrained_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dir = '/s/project/deepMMR/data/fundus/processed/left'\n",
    "dataset_left = Fundus_Left_Right_Combined_Dataset(dataset_dir, loader=lambda x: normalize_image(torchvision.io.read_image(x)))\n",
    "train_dataloader_left = DataLoader(dataset_left, batch_size=1024)\n",
    "\n",
    "dataset_dir = '/s/project/deepMMR/data/fundus/processed/right'\n",
    "dataset_right = Fundus_Left_Right_Combined_Dataset(dataset_dir, loader=lambda x: normalize_image(torchvision.io.read_image(x)))\n",
    "train_dataloader_right = DataLoader(dataset_right, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation - Pretrained ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Process inputs: 100%|██████████| 87/87 [57:44<00:00, 39.82s/it] \n",
      "Process inputs:  48%|████▊     | 42/88 [30:21<32:52, 42.89s/it] "
     ]
    }
   ],
   "source": [
    "model = pretrained_pca.ImageEncoder('resnet50').to(device)\n",
    "features_left, labels_left = pretrained_pca.extract_features(model, train_dataloader_left, device)\n",
    "features_right, labels_right = pretrained_pca.extract_features(model, train_dataloader_right, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_left, features_left)}\n",
    "data_right = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_right, features_right)}\n",
    "data = {label: np.concatenate([feature_left, data_right[label]]) for (label, feature_left) in data_left.items() if label in data_right.keys()}\n",
    "pca = Sklearn_PCA(n_components=128) # 10\n",
    "embeddings = pca.fit_transform(np.stack(data.values()))\n",
    "minimum_variance_explained = 0.8\n",
    "pca_s = pca.explained_variance_ratio_[np.cumsum(pca.explained_variance_ratio_) < minimum_variance_explained]\n",
    "\n",
    "embeddings = embeddings[:, range(len(pca_s))] \n",
    "\n",
    "df = pd.DataFrame(embeddings, index=data.keys(), columns=[f'pca_{num}' for num in range(embeddings.shape[1])])\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca_raw.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_41</th>\n",
       "      <th>pca_42</th>\n",
       "      <th>pca_43</th>\n",
       "      <th>pca_44</th>\n",
       "      <th>pca_45</th>\n",
       "      <th>pca_46</th>\n",
       "      <th>pca_47</th>\n",
       "      <th>pca_48</th>\n",
       "      <th>pca_49</th>\n",
       "      <th>pca_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000066</th>\n",
       "      <td>-5.446280</td>\n",
       "      <td>2.134828</td>\n",
       "      <td>-4.652717</td>\n",
       "      <td>-2.125299</td>\n",
       "      <td>0.580376</td>\n",
       "      <td>0.505437</td>\n",
       "      <td>3.645508</td>\n",
       "      <td>-1.465071</td>\n",
       "      <td>0.559960</td>\n",
       "      <td>-0.148222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353012</td>\n",
       "      <td>0.038454</td>\n",
       "      <td>0.205035</td>\n",
       "      <td>-0.641453</td>\n",
       "      <td>0.869113</td>\n",
       "      <td>0.092259</td>\n",
       "      <td>-0.582056</td>\n",
       "      <td>1.186516</td>\n",
       "      <td>-0.610516</td>\n",
       "      <td>-0.408618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000156</th>\n",
       "      <td>-8.319563</td>\n",
       "      <td>-0.242977</td>\n",
       "      <td>0.330990</td>\n",
       "      <td>2.693621</td>\n",
       "      <td>0.226985</td>\n",
       "      <td>-0.173033</td>\n",
       "      <td>0.044034</td>\n",
       "      <td>0.841468</td>\n",
       "      <td>-0.099231</td>\n",
       "      <td>-0.782438</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.260801</td>\n",
       "      <td>0.136870</td>\n",
       "      <td>0.088421</td>\n",
       "      <td>-0.792122</td>\n",
       "      <td>-0.942989</td>\n",
       "      <td>-0.917753</td>\n",
       "      <td>0.167208</td>\n",
       "      <td>-1.023388</td>\n",
       "      <td>-0.054315</td>\n",
       "      <td>0.599594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>-7.162394</td>\n",
       "      <td>-0.387870</td>\n",
       "      <td>-1.151493</td>\n",
       "      <td>1.097107</td>\n",
       "      <td>3.034690</td>\n",
       "      <td>-2.266430</td>\n",
       "      <td>-0.223179</td>\n",
       "      <td>-0.279714</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>0.161026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672399</td>\n",
       "      <td>-0.107862</td>\n",
       "      <td>0.902505</td>\n",
       "      <td>0.103369</td>\n",
       "      <td>0.715633</td>\n",
       "      <td>-0.988445</td>\n",
       "      <td>-0.291919</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>-0.161655</td>\n",
       "      <td>-0.139666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>7.118132</td>\n",
       "      <td>1.133620</td>\n",
       "      <td>1.888029</td>\n",
       "      <td>1.358146</td>\n",
       "      <td>0.974229</td>\n",
       "      <td>0.119056</td>\n",
       "      <td>2.924170</td>\n",
       "      <td>-3.068111</td>\n",
       "      <td>-3.560253</td>\n",
       "      <td>-1.671859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467257</td>\n",
       "      <td>1.129952</td>\n",
       "      <td>1.485040</td>\n",
       "      <td>-0.275029</td>\n",
       "      <td>-1.220480</td>\n",
       "      <td>-0.125073</td>\n",
       "      <td>0.981571</td>\n",
       "      <td>-0.995944</td>\n",
       "      <td>0.407328</td>\n",
       "      <td>-0.853552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000378</th>\n",
       "      <td>-3.639200</td>\n",
       "      <td>-0.193422</td>\n",
       "      <td>-4.519847</td>\n",
       "      <td>-3.138984</td>\n",
       "      <td>4.326903</td>\n",
       "      <td>-0.346467</td>\n",
       "      <td>-1.569447</td>\n",
       "      <td>-1.438142</td>\n",
       "      <td>0.437637</td>\n",
       "      <td>0.478612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138112</td>\n",
       "      <td>0.243413</td>\n",
       "      <td>0.888183</td>\n",
       "      <td>0.624756</td>\n",
       "      <td>-0.050007</td>\n",
       "      <td>-0.380207</td>\n",
       "      <td>-0.709729</td>\n",
       "      <td>1.088905</td>\n",
       "      <td>0.890469</td>\n",
       "      <td>-0.371500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823925</th>\n",
       "      <td>-4.455645</td>\n",
       "      <td>1.548255</td>\n",
       "      <td>1.318259</td>\n",
       "      <td>1.836927</td>\n",
       "      <td>-2.422237</td>\n",
       "      <td>-3.076377</td>\n",
       "      <td>1.413838</td>\n",
       "      <td>-1.080322</td>\n",
       "      <td>2.505049</td>\n",
       "      <td>-1.520907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088513</td>\n",
       "      <td>-0.649545</td>\n",
       "      <td>0.300166</td>\n",
       "      <td>-0.139134</td>\n",
       "      <td>0.258432</td>\n",
       "      <td>0.461719</td>\n",
       "      <td>-0.504943</td>\n",
       "      <td>0.859834</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>-0.095109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823932</th>\n",
       "      <td>-3.649822</td>\n",
       "      <td>2.648258</td>\n",
       "      <td>2.238149</td>\n",
       "      <td>6.375959</td>\n",
       "      <td>-3.792537</td>\n",
       "      <td>1.586219</td>\n",
       "      <td>0.554872</td>\n",
       "      <td>-1.598632</td>\n",
       "      <td>-1.841741</td>\n",
       "      <td>-1.482859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415452</td>\n",
       "      <td>0.231903</td>\n",
       "      <td>-1.232324</td>\n",
       "      <td>0.119146</td>\n",
       "      <td>0.348567</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>-0.113081</td>\n",
       "      <td>-0.491218</td>\n",
       "      <td>-0.075475</td>\n",
       "      <td>-0.585068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823981</th>\n",
       "      <td>-1.584543</td>\n",
       "      <td>1.011757</td>\n",
       "      <td>6.513752</td>\n",
       "      <td>-1.810544</td>\n",
       "      <td>1.136091</td>\n",
       "      <td>2.039510</td>\n",
       "      <td>1.944103</td>\n",
       "      <td>-1.083197</td>\n",
       "      <td>2.520791</td>\n",
       "      <td>1.933523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062662</td>\n",
       "      <td>-0.135144</td>\n",
       "      <td>0.111591</td>\n",
       "      <td>-0.342395</td>\n",
       "      <td>-0.433655</td>\n",
       "      <td>0.361703</td>\n",
       "      <td>0.123229</td>\n",
       "      <td>-0.903594</td>\n",
       "      <td>-0.113467</td>\n",
       "      <td>0.142126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824010</th>\n",
       "      <td>-5.417394</td>\n",
       "      <td>-1.422743</td>\n",
       "      <td>2.862769</td>\n",
       "      <td>1.065950</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>1.044797</td>\n",
       "      <td>1.703717</td>\n",
       "      <td>-0.196381</td>\n",
       "      <td>-2.116461</td>\n",
       "      <td>-0.533645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003317</td>\n",
       "      <td>0.531032</td>\n",
       "      <td>0.670145</td>\n",
       "      <td>-0.412963</td>\n",
       "      <td>-0.848876</td>\n",
       "      <td>-0.568218</td>\n",
       "      <td>0.165730</td>\n",
       "      <td>-0.633980</td>\n",
       "      <td>0.374417</td>\n",
       "      <td>-0.230644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824044</th>\n",
       "      <td>10.568565</td>\n",
       "      <td>-3.411498</td>\n",
       "      <td>-3.903324</td>\n",
       "      <td>6.118312</td>\n",
       "      <td>6.941116</td>\n",
       "      <td>-3.587905</td>\n",
       "      <td>0.628927</td>\n",
       "      <td>-2.270216</td>\n",
       "      <td>-1.499383</td>\n",
       "      <td>-0.767047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352854</td>\n",
       "      <td>-0.572068</td>\n",
       "      <td>0.693904</td>\n",
       "      <td>-0.257688</td>\n",
       "      <td>-0.858290</td>\n",
       "      <td>-0.701095</td>\n",
       "      <td>-0.429508</td>\n",
       "      <td>-1.081533</td>\n",
       "      <td>-2.071490</td>\n",
       "      <td>1.268018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85239 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pca_0     pca_1     pca_2     pca_3     pca_4     pca_5   \n",
       "eid                                                                    \n",
       "1000066  -5.446280  2.134828 -4.652717 -2.125299  0.580376  0.505437  \\\n",
       "1000156  -8.319563 -0.242977  0.330990  2.693621  0.226985 -0.173033   \n",
       "1000199  -7.162394 -0.387870 -1.151493  1.097107  3.034690 -2.266430   \n",
       "1000301   7.118132  1.133620  1.888029  1.358146  0.974229  0.119056   \n",
       "1000378  -3.639200 -0.193422 -4.519847 -3.138984  4.326903 -0.346467   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "3823925  -4.455645  1.548255  1.318259  1.836927 -2.422237 -3.076377   \n",
       "3823932  -3.649822  2.648258  2.238149  6.375959 -3.792537  1.586219   \n",
       "3823981  -1.584543  1.011757  6.513752 -1.810544  1.136091  2.039510   \n",
       "3824010  -5.417394 -1.422743  2.862769  1.065950  0.030327  1.044797   \n",
       "3824044  10.568565 -3.411498 -3.903324  6.118312  6.941116 -3.587905   \n",
       "\n",
       "            pca_6     pca_7     pca_8     pca_9  ...    pca_41    pca_42   \n",
       "eid                                              ...                       \n",
       "1000066  3.645508 -1.465071  0.559960 -0.148222  ...  0.353012  0.038454  \\\n",
       "1000156  0.044034  0.841468 -0.099231 -0.782438  ... -1.260801  0.136870   \n",
       "1000199 -0.223179 -0.279714 -0.669099  0.161026  ... -0.672399 -0.107862   \n",
       "1000301  2.924170 -3.068111 -3.560253 -1.671859  ...  0.467257  1.129952   \n",
       "1000378 -1.569447 -1.438142  0.437637  0.478612  ...  0.138112  0.243413   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "3823925  1.413838 -1.080322  2.505049 -1.520907  ...  0.088513 -0.649545   \n",
       "3823932  0.554872 -1.598632 -1.841741 -1.482859  ... -0.415452  0.231903   \n",
       "3823981  1.944103 -1.083197  2.520791  1.933523  ...  0.062662 -0.135144   \n",
       "3824010  1.703717 -0.196381 -2.116461 -0.533645  ... -0.003317  0.531032   \n",
       "3824044  0.628927 -2.270216 -1.499383 -0.767047  ...  1.352854 -0.572068   \n",
       "\n",
       "           pca_43    pca_44    pca_45    pca_46    pca_47    pca_48    pca_49   \n",
       "eid                                                                             \n",
       "1000066  0.205035 -0.641453  0.869113  0.092259 -0.582056  1.186516 -0.610516  \\\n",
       "1000156  0.088421 -0.792122 -0.942989 -0.917753  0.167208 -1.023388 -0.054315   \n",
       "1000199  0.902505  0.103369  0.715633 -0.988445 -0.291919  0.149660 -0.161655   \n",
       "1000301  1.485040 -0.275029 -1.220480 -0.125073  0.981571 -0.995944  0.407328   \n",
       "1000378  0.888183  0.624756 -0.050007 -0.380207 -0.709729  1.088905  0.890469   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3823925  0.300166 -0.139134  0.258432  0.461719 -0.504943  0.859834  0.008174   \n",
       "3823932 -1.232324  0.119146  0.348567  0.501581 -0.113081 -0.491218 -0.075475   \n",
       "3823981  0.111591 -0.342395 -0.433655  0.361703  0.123229 -0.903594 -0.113467   \n",
       "3824010  0.670145 -0.412963 -0.848876 -0.568218  0.165730 -0.633980  0.374417   \n",
       "3824044  0.693904 -0.257688 -0.858290 -0.701095 -0.429508 -1.081533 -2.071490   \n",
       "\n",
       "           pca_50  \n",
       "eid                \n",
       "1000066 -0.408618  \n",
       "1000156  0.599594  \n",
       "1000199 -0.139666  \n",
       "1000301 -0.853552  \n",
       "1000378 -0.371500  \n",
       "...           ...  \n",
       "3823925 -0.095109  \n",
       "3823932 -0.585068  \n",
       "3823981  0.142126  \n",
       "3824010 -0.230644  \n",
       "3824044  1.268018  \n",
       "\n",
       "[85239 rows x 51 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca_raw.parquet')\n",
    "df.index = df.index.str.split('_').str[0]\n",
    "df.index.names = ['eid']\n",
    "duplicates = df.index.duplicated(keep='first')\n",
    "df = df[~duplicates]\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df.index = df.index.str.split('_', expand=True)\n",
    "df.index.names = ['eid', 'fid', 'instance_id', 'array_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000066</th>\n",
       "      <td>-2.252839</td>\n",
       "      <td>3.066601</td>\n",
       "      <td>-2.913292</td>\n",
       "      <td>-2.328768</td>\n",
       "      <td>1.500444</td>\n",
       "      <td>1.818484</td>\n",
       "      <td>-1.092669</td>\n",
       "      <td>-1.270074</td>\n",
       "      <td>-1.512550</td>\n",
       "      <td>3.528600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000156</th>\n",
       "      <td>-5.963784</td>\n",
       "      <td>0.325908</td>\n",
       "      <td>-1.809769</td>\n",
       "      <td>2.433903</td>\n",
       "      <td>-0.624344</td>\n",
       "      <td>0.911276</td>\n",
       "      <td>-0.220119</td>\n",
       "      <td>0.139989</td>\n",
       "      <td>-0.655710</td>\n",
       "      <td>1.087488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>-4.968379</td>\n",
       "      <td>-0.170561</td>\n",
       "      <td>-0.363203</td>\n",
       "      <td>1.222055</td>\n",
       "      <td>2.232448</td>\n",
       "      <td>-0.122127</td>\n",
       "      <td>-1.113042</td>\n",
       "      <td>-0.046429</td>\n",
       "      <td>-1.952182</td>\n",
       "      <td>0.913763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>6.130622</td>\n",
       "      <td>1.322871</td>\n",
       "      <td>1.488849</td>\n",
       "      <td>-0.134390</td>\n",
       "      <td>1.098978</td>\n",
       "      <td>0.586573</td>\n",
       "      <td>-3.117746</td>\n",
       "      <td>-1.187186</td>\n",
       "      <td>0.740730</td>\n",
       "      <td>-0.114611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000378</th>\n",
       "      <td>-4.354016</td>\n",
       "      <td>-0.258280</td>\n",
       "      <td>-2.338870</td>\n",
       "      <td>-0.358884</td>\n",
       "      <td>3.314417</td>\n",
       "      <td>1.889463</td>\n",
       "      <td>-0.674396</td>\n",
       "      <td>2.056707</td>\n",
       "      <td>-1.619832</td>\n",
       "      <td>-3.547954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025959</th>\n",
       "      <td>2.996337</td>\n",
       "      <td>-0.728765</td>\n",
       "      <td>2.447221</td>\n",
       "      <td>-1.584065</td>\n",
       "      <td>-2.570893</td>\n",
       "      <td>-0.322580</td>\n",
       "      <td>-1.135632</td>\n",
       "      <td>0.223566</td>\n",
       "      <td>-0.775059</td>\n",
       "      <td>-1.589258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026028</th>\n",
       "      <td>4.927389</td>\n",
       "      <td>3.239777</td>\n",
       "      <td>0.903430</td>\n",
       "      <td>4.418314</td>\n",
       "      <td>2.202457</td>\n",
       "      <td>2.384530</td>\n",
       "      <td>1.282864</td>\n",
       "      <td>-0.437195</td>\n",
       "      <td>-0.633742</td>\n",
       "      <td>0.861229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026072</th>\n",
       "      <td>8.695135</td>\n",
       "      <td>-3.834220</td>\n",
       "      <td>-2.078501</td>\n",
       "      <td>2.316255</td>\n",
       "      <td>-0.579175</td>\n",
       "      <td>-1.012689</td>\n",
       "      <td>2.724683</td>\n",
       "      <td>0.646925</td>\n",
       "      <td>0.066713</td>\n",
       "      <td>-1.181772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026083</th>\n",
       "      <td>1.622089</td>\n",
       "      <td>0.356023</td>\n",
       "      <td>-1.366311</td>\n",
       "      <td>-1.810328</td>\n",
       "      <td>-0.948143</td>\n",
       "      <td>0.265917</td>\n",
       "      <td>0.993383</td>\n",
       "      <td>-0.537539</td>\n",
       "      <td>-0.051097</td>\n",
       "      <td>0.443448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026179</th>\n",
       "      <td>1.174178</td>\n",
       "      <td>-1.845445</td>\n",
       "      <td>-4.586893</td>\n",
       "      <td>-4.290789</td>\n",
       "      <td>2.636322</td>\n",
       "      <td>2.751485</td>\n",
       "      <td>-0.067389</td>\n",
       "      <td>0.927045</td>\n",
       "      <td>-0.518355</td>\n",
       "      <td>2.040406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86195 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pca_0     pca_1     pca_2     pca_3     pca_4     pca_5     pca_6   \n",
       "eid                                                                             \n",
       "1000066 -2.252839  3.066601 -2.913292 -2.328768  1.500444  1.818484 -1.092669  \\\n",
       "1000156 -5.963784  0.325908 -1.809769  2.433903 -0.624344  0.911276 -0.220119   \n",
       "1000199 -4.968379 -0.170561 -0.363203  1.222055  2.232448 -0.122127 -1.113042   \n",
       "1000301  6.130622  1.322871  1.488849 -0.134390  1.098978  0.586573 -3.117746   \n",
       "1000378 -4.354016 -0.258280 -2.338870 -0.358884  3.314417  1.889463 -0.674396   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "6025959  2.996337 -0.728765  2.447221 -1.584065 -2.570893 -0.322580 -1.135632   \n",
       "6026028  4.927389  3.239777  0.903430  4.418314  2.202457  2.384530  1.282864   \n",
       "6026072  8.695135 -3.834220 -2.078501  2.316255 -0.579175 -1.012689  2.724683   \n",
       "6026083  1.622089  0.356023 -1.366311 -1.810328 -0.948143  0.265917  0.993383   \n",
       "6026179  1.174178 -1.845445 -4.586893 -4.290789  2.636322  2.751485 -0.067389   \n",
       "\n",
       "            pca_7     pca_8     pca_9  \n",
       "eid                                    \n",
       "1000066 -1.270074 -1.512550  3.528600  \n",
       "1000156  0.139989 -0.655710  1.087488  \n",
       "1000199 -0.046429 -1.952182  0.913763  \n",
       "1000301 -1.187186  0.740730 -0.114611  \n",
       "1000378  2.056707 -1.619832 -3.547954  \n",
       "...           ...       ...       ...  \n",
       "6025959  0.223566 -0.775059 -1.589258  \n",
       "6026028 -0.437195 -0.633742  0.861229  \n",
       "6026072  0.646925  0.066713 -1.181772  \n",
       "6026083 -0.537539 -0.051097  0.443448  \n",
       "6026179  0.927045 -0.518355  2.040406  \n",
       "\n",
       "[86195 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collapsed = df.reset_index().groupby('eid').last()\n",
    "df_collapsed = df_collapsed.drop(['fid', 'instance_id', 'array_id'], axis=1)\n",
    "df_collapsed.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df_collapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(embeddings: torch.Tensor, labels: torch.Tensor, device) -> nn.Module:\n",
    "    # Train a linear model\n",
    "    linear_model = nn.Linear(embeddings.shape[1], len(torch.unique(labels))).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr=3e-4)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(5000):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = linear_model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return linear_model\n",
    "\n",
    "def plot_roc_curve(labels: List[int], scores: List[float]):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train a linear model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_linear_model\u001b[49m(embeddings_tensor, labels_tensor, device)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate scores using the linear model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m scores \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(linear_model(embeddings_tensor))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train a linear model\n",
    "linear_model = train_linear_model(embeddings_tensor, labels_tensor, device)\n",
    "\n",
    "# Calculate scores using the linear model\n",
    "scores = nn.functional.softmax(linear_model(embeddings_tensor)).detach().cpu().numpy()\n",
    "# Plot ROC curve for each class\n",
    "for class_label in torch.unique(labels_tensor):\n",
    "    class_scores = scores[:, class_label]\n",
    "    class_labels = [1 if label == class_label else 0 for label in labels_tensor]\n",
    "    plot_roc_curve(class_labels, class_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation - Pretrained SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pytorch_lightning/utilities/migration/migration.py:195: PossibleUserWarning: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "  rank_zero_warn(\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.0.4 to v1.9.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file https:/pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt`\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:234: UnderReviewWarning: The feature SimCLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  obj = cls(**_cls_kwargs)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/simclr/simclr_module.py:138: UnderReviewWarning: The feature resnet50 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return backbone(first_conv=self.first_conv, maxpool1=self.maxpool1, return_all_feature_maps=False)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:321: UnderReviewWarning: The feature _resnet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return _resnet(\"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:281: UnderReviewWarning: The feature ResNet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  model = ResNet(block, layers, **kwargs)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:223: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  conv1x1(self.inplanes, planes * block.expansion, stride),\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:229: UnderReviewWarning: The feature Bottleneck is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  block(\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:110: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/simclr/simclr_module.py:126: UnderReviewWarning: The feature Projection is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.projection = Projection(input_dim=self.hidden_mlp, hidden_dim=self.hidden_mlp, output_dim=self.feat_dim)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:255: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['non_linear_evaluator.block_forward.2.weight', 'non_linear_evaluator.block_forward.2.bias']\n",
      "  rank_zero_warn(\n",
      "Process inputs: 100%|██████████| 87/87 [1:37:01<00:00, 66.92s/it]\n",
      "Process inputs: 100%|██████████| 88/88 [1:24:29<00:00, 57.61s/it]\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# model\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "model = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "model.to(device)\n",
    "model.freeze()\n",
    "\n",
    "def extract_features(model: nn.Module, dataloader: DataLoader, device: torch.device) -> np.ndarray:\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, file_names in tqdm(dataloader, desc='Process inputs'):\n",
    "            output = model(inputs.to(device))\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.extend([f.split('.')[0] for f in file_names])\n",
    "    return np.concatenate(features, axis=0).squeeze(), labels\n",
    "\n",
    "features_left, labels_left = extract_features(model, train_dataloader_left, device)\n",
    "features_right, labels_right = extract_features(model, train_dataloader_right, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "data_left = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_left, features_left)}\n",
    "data_right = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_right, features_right)}\n",
    "data = {label: np.concatenate([feature_left, data_right[label]]) for (label, feature_left) in data_left.items() if label in data_right.keys()}\n",
    "\n",
    "df = pd.DataFrame(np.stack(data.values()), index=data.keys(), columns=[f'feature_{num}' for num in range(np.stack(data.values()).shape[1])])\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_raw.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_raw.parquet')\n",
    "\n",
    "df_raw.index.names = ['eid']\n",
    "df_raw.index = df_raw.index.str.split('_').str[0]\n",
    "df_raw.index.names = ['eid']\n",
    "duplicates = df_raw.index.duplicated(keep='first')\n",
    "df_raw = df_raw[~duplicates]\n",
    "\n",
    "pca = Sklearn_PCA(n_components=256) # 10\n",
    "embeddings = pca.fit_transform(np.stack(df_raw.values))\n",
    "df = pd.DataFrame(embeddings, index=df_raw.index, columns=[f'pca_{num}' for num in range(embeddings.shape[1])])\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_pca.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000066</th>\n",
       "      <td>-1.124531</td>\n",
       "      <td>0.476144</td>\n",
       "      <td>0.039057</td>\n",
       "      <td>0.037099</td>\n",
       "      <td>0.415730</td>\n",
       "      <td>0.050869</td>\n",
       "      <td>-0.071730</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>0.515702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000156</th>\n",
       "      <td>-1.246989</td>\n",
       "      <td>-0.333761</td>\n",
       "      <td>0.595704</td>\n",
       "      <td>-0.233015</td>\n",
       "      <td>-0.303992</td>\n",
       "      <td>-0.124384</td>\n",
       "      <td>0.152929</td>\n",
       "      <td>-0.035439</td>\n",
       "      <td>0.224985</td>\n",
       "      <td>-0.022164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>-1.545924</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>0.332943</td>\n",
       "      <td>0.215149</td>\n",
       "      <td>-0.147210</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>-0.025074</td>\n",
       "      <td>-0.034308</td>\n",
       "      <td>-0.010866</td>\n",
       "      <td>-0.100134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>1.464271</td>\n",
       "      <td>0.471742</td>\n",
       "      <td>0.117708</td>\n",
       "      <td>-0.446180</td>\n",
       "      <td>0.069569</td>\n",
       "      <td>-0.074620</td>\n",
       "      <td>-0.111770</td>\n",
       "      <td>-0.483076</td>\n",
       "      <td>0.171306</td>\n",
       "      <td>0.125713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000378</th>\n",
       "      <td>-1.011024</td>\n",
       "      <td>-0.077450</td>\n",
       "      <td>0.054507</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>-0.424258</td>\n",
       "      <td>0.304522</td>\n",
       "      <td>-0.272214</td>\n",
       "      <td>-0.117854</td>\n",
       "      <td>0.375444</td>\n",
       "      <td>-0.005743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823925</th>\n",
       "      <td>-0.721995</td>\n",
       "      <td>-0.035558</td>\n",
       "      <td>-0.509513</td>\n",
       "      <td>-0.167597</td>\n",
       "      <td>-0.022988</td>\n",
       "      <td>-0.273178</td>\n",
       "      <td>-0.185490</td>\n",
       "      <td>0.045779</td>\n",
       "      <td>-0.054213</td>\n",
       "      <td>0.274207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823932</th>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.952701</td>\n",
       "      <td>0.346640</td>\n",
       "      <td>-0.476639</td>\n",
       "      <td>0.020480</td>\n",
       "      <td>0.344963</td>\n",
       "      <td>0.568104</td>\n",
       "      <td>-0.512069</td>\n",
       "      <td>0.072603</td>\n",
       "      <td>0.214979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823981</th>\n",
       "      <td>0.236588</td>\n",
       "      <td>0.156204</td>\n",
       "      <td>-0.349229</td>\n",
       "      <td>-0.943248</td>\n",
       "      <td>-0.027832</td>\n",
       "      <td>-0.306307</td>\n",
       "      <td>-0.173657</td>\n",
       "      <td>0.403887</td>\n",
       "      <td>-0.052307</td>\n",
       "      <td>-0.143568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824010</th>\n",
       "      <td>-0.301947</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>-0.063579</td>\n",
       "      <td>-0.485457</td>\n",
       "      <td>0.322031</td>\n",
       "      <td>-0.634809</td>\n",
       "      <td>0.067884</td>\n",
       "      <td>-0.181177</td>\n",
       "      <td>0.094405</td>\n",
       "      <td>0.288821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824044</th>\n",
       "      <td>1.846912</td>\n",
       "      <td>0.262696</td>\n",
       "      <td>1.880477</td>\n",
       "      <td>0.183165</td>\n",
       "      <td>0.186425</td>\n",
       "      <td>-0.109127</td>\n",
       "      <td>-0.732211</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>0.159945</td>\n",
       "      <td>0.431064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85239 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pca_0     pca_1     pca_2     pca_3     pca_4     pca_5     pca_6   \n",
       "eid                                                                             \n",
       "1000066 -1.124531  0.476144  0.039057  0.037099  0.415730  0.050869 -0.071730  \\\n",
       "1000156 -1.246989 -0.333761  0.595704 -0.233015 -0.303992 -0.124384  0.152929   \n",
       "1000199 -1.545924  0.019440  0.332943  0.215149 -0.147210  0.001268 -0.025074   \n",
       "1000301  1.464271  0.471742  0.117708 -0.446180  0.069569 -0.074620 -0.111770   \n",
       "1000378 -1.011024 -0.077450  0.054507  0.241299 -0.424258  0.304522 -0.272214   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3823925 -0.721995 -0.035558 -0.509513 -0.167597 -0.022988 -0.273178 -0.185490   \n",
       "3823932  0.062510  0.952701  0.346640 -0.476639  0.020480  0.344963  0.568104   \n",
       "3823981  0.236588  0.156204 -0.349229 -0.943248 -0.027832 -0.306307 -0.173657   \n",
       "3824010 -0.301947  0.019988 -0.063579 -0.485457  0.322031 -0.634809  0.067884   \n",
       "3824044  1.846912  0.262696  1.880477  0.183165  0.186425 -0.109127 -0.732211   \n",
       "\n",
       "            pca_7     pca_8     pca_9  \n",
       "eid                                    \n",
       "1000066  0.004496 -0.004564  0.515702  \n",
       "1000156 -0.035439  0.224985 -0.022164  \n",
       "1000199 -0.034308 -0.010866 -0.100134  \n",
       "1000301 -0.483076  0.171306  0.125713  \n",
       "1000378 -0.117854  0.375444 -0.005743  \n",
       "...           ...       ...       ...  \n",
       "3823925  0.045779 -0.054213  0.274207  \n",
       "3823932 -0.512069  0.072603  0.214979  \n",
       "3823981  0.403887 -0.052307 -0.143568  \n",
       "3824010 -0.181177  0.094405  0.288821  \n",
       "3824044 -0.166702  0.159945  0.431064  \n",
       "\n",
       "[85239 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_pca.parquet')\n",
    "df = df_raw.iloc[:, range(10)]\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_pca_10.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-deepMMR]",
   "language": "python",
   "name": "conda-env-anaconda-deepMMR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
