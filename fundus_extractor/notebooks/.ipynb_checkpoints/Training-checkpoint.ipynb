{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Tuple, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torchvision.datasets import DatasetFolder, ImageFolder\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.decomposition import PCA as Sklearn_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from fundus_extractor.utils.general import imshow, normalize_image\n",
    "from fundus_extractor.utils.datasets import Fundus_Left_Right_Combined_Dataset\n",
    "from fundus_extractor.models import pretrained_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dir = '/s/project/deepMMR/data/fundus/processed/left'\n",
    "dataset_left = Fundus_Left_Right_Combined_Dataset(dataset_dir, loader=lambda x: normalize_image(torchvision.io.read_image(x)))\n",
    "train_dataloader_left = DataLoader(dataset_left, batch_size=1024)\n",
    "\n",
    "dataset_dir = '/s/project/deepMMR/data/fundus/processed/right'\n",
    "dataset_right = Fundus_Left_Right_Combined_Dataset(dataset_dir, loader=lambda x: normalize_image(torchvision.io.read_image(x)))\n",
    "train_dataloader_right = DataLoader(dataset_right, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Evaluation - Pretrained ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Process inputs: 100%|██████████| 87/87 [57:44<00:00, 39.82s/it] \n",
      "Process inputs:  48%|████▊     | 42/88 [30:21<32:52, 42.89s/it] "
     ]
    }
   ],
   "source": [
    "model = pretrained_pca.ImageEncoder('resnet50').to(device)\n",
    "features_left, labels_left = pretrained_pca.extract_features(model, train_dataloader_left, device)\n",
    "features_right, labels_right = pretrained_pca.extract_features(model, train_dataloader_right, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_left, features_left)}\n",
    "data_right = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_right, features_right)}\n",
    "data = {label: np.concatenate([feature_left, data_right[label]]) for (label, feature_left) in data_left.items() if label in data_right.keys()}\n",
    "pca = Sklearn_PCA(n_components=128) # 10\n",
    "embeddings = pca.fit_transform(np.stack(data.values()))\n",
    "minimum_variance_explained = 0.8\n",
    "pca_s = pca.explained_variance_ratio_[np.cumsum(pca.explained_variance_ratio_) < minimum_variance_explained]\n",
    "\n",
    "embeddings = embeddings[:, range(len(pca_s))] \n",
    "\n",
    "df = pd.DataFrame(embeddings, index=data.keys(), columns=[f'pca_{num}' for num in range(embeddings.shape[1])])\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca_raw.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_41</th>\n",
       "      <th>pca_42</th>\n",
       "      <th>pca_43</th>\n",
       "      <th>pca_44</th>\n",
       "      <th>pca_45</th>\n",
       "      <th>pca_46</th>\n",
       "      <th>pca_47</th>\n",
       "      <th>pca_48</th>\n",
       "      <th>pca_49</th>\n",
       "      <th>pca_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000066</th>\n",
       "      <td>-5.446280</td>\n",
       "      <td>2.134828</td>\n",
       "      <td>-4.652717</td>\n",
       "      <td>-2.125299</td>\n",
       "      <td>0.580376</td>\n",
       "      <td>0.505437</td>\n",
       "      <td>3.645508</td>\n",
       "      <td>-1.465071</td>\n",
       "      <td>0.559960</td>\n",
       "      <td>-0.148222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353012</td>\n",
       "      <td>0.038454</td>\n",
       "      <td>0.205035</td>\n",
       "      <td>-0.641453</td>\n",
       "      <td>0.869113</td>\n",
       "      <td>0.092259</td>\n",
       "      <td>-0.582056</td>\n",
       "      <td>1.186516</td>\n",
       "      <td>-0.610516</td>\n",
       "      <td>-0.408618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000156</th>\n",
       "      <td>-8.319563</td>\n",
       "      <td>-0.242977</td>\n",
       "      <td>0.330990</td>\n",
       "      <td>2.693621</td>\n",
       "      <td>0.226985</td>\n",
       "      <td>-0.173033</td>\n",
       "      <td>0.044034</td>\n",
       "      <td>0.841468</td>\n",
       "      <td>-0.099231</td>\n",
       "      <td>-0.782438</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.260801</td>\n",
       "      <td>0.136870</td>\n",
       "      <td>0.088421</td>\n",
       "      <td>-0.792122</td>\n",
       "      <td>-0.942989</td>\n",
       "      <td>-0.917753</td>\n",
       "      <td>0.167208</td>\n",
       "      <td>-1.023388</td>\n",
       "      <td>-0.054315</td>\n",
       "      <td>0.599594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>-7.162394</td>\n",
       "      <td>-0.387870</td>\n",
       "      <td>-1.151493</td>\n",
       "      <td>1.097107</td>\n",
       "      <td>3.034690</td>\n",
       "      <td>-2.266430</td>\n",
       "      <td>-0.223179</td>\n",
       "      <td>-0.279714</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>0.161026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672399</td>\n",
       "      <td>-0.107862</td>\n",
       "      <td>0.902505</td>\n",
       "      <td>0.103369</td>\n",
       "      <td>0.715633</td>\n",
       "      <td>-0.988445</td>\n",
       "      <td>-0.291919</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>-0.161655</td>\n",
       "      <td>-0.139666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>7.118132</td>\n",
       "      <td>1.133620</td>\n",
       "      <td>1.888029</td>\n",
       "      <td>1.358146</td>\n",
       "      <td>0.974229</td>\n",
       "      <td>0.119056</td>\n",
       "      <td>2.924170</td>\n",
       "      <td>-3.068111</td>\n",
       "      <td>-3.560253</td>\n",
       "      <td>-1.671859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467257</td>\n",
       "      <td>1.129952</td>\n",
       "      <td>1.485040</td>\n",
       "      <td>-0.275029</td>\n",
       "      <td>-1.220480</td>\n",
       "      <td>-0.125073</td>\n",
       "      <td>0.981571</td>\n",
       "      <td>-0.995944</td>\n",
       "      <td>0.407328</td>\n",
       "      <td>-0.853552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000378</th>\n",
       "      <td>-3.639200</td>\n",
       "      <td>-0.193422</td>\n",
       "      <td>-4.519847</td>\n",
       "      <td>-3.138984</td>\n",
       "      <td>4.326903</td>\n",
       "      <td>-0.346467</td>\n",
       "      <td>-1.569447</td>\n",
       "      <td>-1.438142</td>\n",
       "      <td>0.437637</td>\n",
       "      <td>0.478612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138112</td>\n",
       "      <td>0.243413</td>\n",
       "      <td>0.888183</td>\n",
       "      <td>0.624756</td>\n",
       "      <td>-0.050007</td>\n",
       "      <td>-0.380207</td>\n",
       "      <td>-0.709729</td>\n",
       "      <td>1.088905</td>\n",
       "      <td>0.890469</td>\n",
       "      <td>-0.371500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823925</th>\n",
       "      <td>-4.455645</td>\n",
       "      <td>1.548255</td>\n",
       "      <td>1.318259</td>\n",
       "      <td>1.836927</td>\n",
       "      <td>-2.422237</td>\n",
       "      <td>-3.076377</td>\n",
       "      <td>1.413838</td>\n",
       "      <td>-1.080322</td>\n",
       "      <td>2.505049</td>\n",
       "      <td>-1.520907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088513</td>\n",
       "      <td>-0.649545</td>\n",
       "      <td>0.300166</td>\n",
       "      <td>-0.139134</td>\n",
       "      <td>0.258432</td>\n",
       "      <td>0.461719</td>\n",
       "      <td>-0.504943</td>\n",
       "      <td>0.859834</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>-0.095109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823932</th>\n",
       "      <td>-3.649822</td>\n",
       "      <td>2.648258</td>\n",
       "      <td>2.238149</td>\n",
       "      <td>6.375959</td>\n",
       "      <td>-3.792537</td>\n",
       "      <td>1.586219</td>\n",
       "      <td>0.554872</td>\n",
       "      <td>-1.598632</td>\n",
       "      <td>-1.841741</td>\n",
       "      <td>-1.482859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415452</td>\n",
       "      <td>0.231903</td>\n",
       "      <td>-1.232324</td>\n",
       "      <td>0.119146</td>\n",
       "      <td>0.348567</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>-0.113081</td>\n",
       "      <td>-0.491218</td>\n",
       "      <td>-0.075475</td>\n",
       "      <td>-0.585068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823981</th>\n",
       "      <td>-1.584543</td>\n",
       "      <td>1.011757</td>\n",
       "      <td>6.513752</td>\n",
       "      <td>-1.810544</td>\n",
       "      <td>1.136091</td>\n",
       "      <td>2.039510</td>\n",
       "      <td>1.944103</td>\n",
       "      <td>-1.083197</td>\n",
       "      <td>2.520791</td>\n",
       "      <td>1.933523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062662</td>\n",
       "      <td>-0.135144</td>\n",
       "      <td>0.111591</td>\n",
       "      <td>-0.342395</td>\n",
       "      <td>-0.433655</td>\n",
       "      <td>0.361703</td>\n",
       "      <td>0.123229</td>\n",
       "      <td>-0.903594</td>\n",
       "      <td>-0.113467</td>\n",
       "      <td>0.142126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824010</th>\n",
       "      <td>-5.417394</td>\n",
       "      <td>-1.422743</td>\n",
       "      <td>2.862769</td>\n",
       "      <td>1.065950</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>1.044797</td>\n",
       "      <td>1.703717</td>\n",
       "      <td>-0.196381</td>\n",
       "      <td>-2.116461</td>\n",
       "      <td>-0.533645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003317</td>\n",
       "      <td>0.531032</td>\n",
       "      <td>0.670145</td>\n",
       "      <td>-0.412963</td>\n",
       "      <td>-0.848876</td>\n",
       "      <td>-0.568218</td>\n",
       "      <td>0.165730</td>\n",
       "      <td>-0.633980</td>\n",
       "      <td>0.374417</td>\n",
       "      <td>-0.230644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824044</th>\n",
       "      <td>10.568565</td>\n",
       "      <td>-3.411498</td>\n",
       "      <td>-3.903324</td>\n",
       "      <td>6.118312</td>\n",
       "      <td>6.941116</td>\n",
       "      <td>-3.587905</td>\n",
       "      <td>0.628927</td>\n",
       "      <td>-2.270216</td>\n",
       "      <td>-1.499383</td>\n",
       "      <td>-0.767047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352854</td>\n",
       "      <td>-0.572068</td>\n",
       "      <td>0.693904</td>\n",
       "      <td>-0.257688</td>\n",
       "      <td>-0.858290</td>\n",
       "      <td>-0.701095</td>\n",
       "      <td>-0.429508</td>\n",
       "      <td>-1.081533</td>\n",
       "      <td>-2.071490</td>\n",
       "      <td>1.268018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85239 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pca_0     pca_1     pca_2     pca_3     pca_4     pca_5   \n",
       "eid                                                                    \n",
       "1000066  -5.446280  2.134828 -4.652717 -2.125299  0.580376  0.505437  \\\n",
       "1000156  -8.319563 -0.242977  0.330990  2.693621  0.226985 -0.173033   \n",
       "1000199  -7.162394 -0.387870 -1.151493  1.097107  3.034690 -2.266430   \n",
       "1000301   7.118132  1.133620  1.888029  1.358146  0.974229  0.119056   \n",
       "1000378  -3.639200 -0.193422 -4.519847 -3.138984  4.326903 -0.346467   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "3823925  -4.455645  1.548255  1.318259  1.836927 -2.422237 -3.076377   \n",
       "3823932  -3.649822  2.648258  2.238149  6.375959 -3.792537  1.586219   \n",
       "3823981  -1.584543  1.011757  6.513752 -1.810544  1.136091  2.039510   \n",
       "3824010  -5.417394 -1.422743  2.862769  1.065950  0.030327  1.044797   \n",
       "3824044  10.568565 -3.411498 -3.903324  6.118312  6.941116 -3.587905   \n",
       "\n",
       "            pca_6     pca_7     pca_8     pca_9  ...    pca_41    pca_42   \n",
       "eid                                              ...                       \n",
       "1000066  3.645508 -1.465071  0.559960 -0.148222  ...  0.353012  0.038454  \\\n",
       "1000156  0.044034  0.841468 -0.099231 -0.782438  ... -1.260801  0.136870   \n",
       "1000199 -0.223179 -0.279714 -0.669099  0.161026  ... -0.672399 -0.107862   \n",
       "1000301  2.924170 -3.068111 -3.560253 -1.671859  ...  0.467257  1.129952   \n",
       "1000378 -1.569447 -1.438142  0.437637  0.478612  ...  0.138112  0.243413   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "3823925  1.413838 -1.080322  2.505049 -1.520907  ...  0.088513 -0.649545   \n",
       "3823932  0.554872 -1.598632 -1.841741 -1.482859  ... -0.415452  0.231903   \n",
       "3823981  1.944103 -1.083197  2.520791  1.933523  ...  0.062662 -0.135144   \n",
       "3824010  1.703717 -0.196381 -2.116461 -0.533645  ... -0.003317  0.531032   \n",
       "3824044  0.628927 -2.270216 -1.499383 -0.767047  ...  1.352854 -0.572068   \n",
       "\n",
       "           pca_43    pca_44    pca_45    pca_46    pca_47    pca_48    pca_49   \n",
       "eid                                                                             \n",
       "1000066  0.205035 -0.641453  0.869113  0.092259 -0.582056  1.186516 -0.610516  \\\n",
       "1000156  0.088421 -0.792122 -0.942989 -0.917753  0.167208 -1.023388 -0.054315   \n",
       "1000199  0.902505  0.103369  0.715633 -0.988445 -0.291919  0.149660 -0.161655   \n",
       "1000301  1.485040 -0.275029 -1.220480 -0.125073  0.981571 -0.995944  0.407328   \n",
       "1000378  0.888183  0.624756 -0.050007 -0.380207 -0.709729  1.088905  0.890469   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3823925  0.300166 -0.139134  0.258432  0.461719 -0.504943  0.859834  0.008174   \n",
       "3823932 -1.232324  0.119146  0.348567  0.501581 -0.113081 -0.491218 -0.075475   \n",
       "3823981  0.111591 -0.342395 -0.433655  0.361703  0.123229 -0.903594 -0.113467   \n",
       "3824010  0.670145 -0.412963 -0.848876 -0.568218  0.165730 -0.633980  0.374417   \n",
       "3824044  0.693904 -0.257688 -0.858290 -0.701095 -0.429508 -1.081533 -2.071490   \n",
       "\n",
       "           pca_50  \n",
       "eid                \n",
       "1000066 -0.408618  \n",
       "1000156  0.599594  \n",
       "1000199 -0.139666  \n",
       "1000301 -0.853552  \n",
       "1000378 -0.371500  \n",
       "...           ...  \n",
       "3823925 -0.095109  \n",
       "3823932 -0.585068  \n",
       "3823981  0.142126  \n",
       "3824010 -0.230644  \n",
       "3824044  1.268018  \n",
       "\n",
       "[85239 rows x 51 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca_raw.parquet')\n",
    "df.index = df.index.str.split('_').str[0]\n",
    "df.index.names = ['eid']\n",
    "duplicates = df.index.duplicated(keep='first')\n",
    "df = df[~duplicates]\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df.index = df.index.str.split('_', expand=True)\n",
    "df.index.names = ['eid', 'fid', 'instance_id', 'array_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000066</th>\n",
       "      <td>-2.252839</td>\n",
       "      <td>3.066601</td>\n",
       "      <td>-2.913292</td>\n",
       "      <td>-2.328768</td>\n",
       "      <td>1.500444</td>\n",
       "      <td>1.818484</td>\n",
       "      <td>-1.092669</td>\n",
       "      <td>-1.270074</td>\n",
       "      <td>-1.512550</td>\n",
       "      <td>3.528600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000156</th>\n",
       "      <td>-5.963784</td>\n",
       "      <td>0.325908</td>\n",
       "      <td>-1.809769</td>\n",
       "      <td>2.433903</td>\n",
       "      <td>-0.624344</td>\n",
       "      <td>0.911276</td>\n",
       "      <td>-0.220119</td>\n",
       "      <td>0.139989</td>\n",
       "      <td>-0.655710</td>\n",
       "      <td>1.087488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>-4.968379</td>\n",
       "      <td>-0.170561</td>\n",
       "      <td>-0.363203</td>\n",
       "      <td>1.222055</td>\n",
       "      <td>2.232448</td>\n",
       "      <td>-0.122127</td>\n",
       "      <td>-1.113042</td>\n",
       "      <td>-0.046429</td>\n",
       "      <td>-1.952182</td>\n",
       "      <td>0.913763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>6.130622</td>\n",
       "      <td>1.322871</td>\n",
       "      <td>1.488849</td>\n",
       "      <td>-0.134390</td>\n",
       "      <td>1.098978</td>\n",
       "      <td>0.586573</td>\n",
       "      <td>-3.117746</td>\n",
       "      <td>-1.187186</td>\n",
       "      <td>0.740730</td>\n",
       "      <td>-0.114611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000378</th>\n",
       "      <td>-4.354016</td>\n",
       "      <td>-0.258280</td>\n",
       "      <td>-2.338870</td>\n",
       "      <td>-0.358884</td>\n",
       "      <td>3.314417</td>\n",
       "      <td>1.889463</td>\n",
       "      <td>-0.674396</td>\n",
       "      <td>2.056707</td>\n",
       "      <td>-1.619832</td>\n",
       "      <td>-3.547954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025959</th>\n",
       "      <td>2.996337</td>\n",
       "      <td>-0.728765</td>\n",
       "      <td>2.447221</td>\n",
       "      <td>-1.584065</td>\n",
       "      <td>-2.570893</td>\n",
       "      <td>-0.322580</td>\n",
       "      <td>-1.135632</td>\n",
       "      <td>0.223566</td>\n",
       "      <td>-0.775059</td>\n",
       "      <td>-1.589258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026028</th>\n",
       "      <td>4.927389</td>\n",
       "      <td>3.239777</td>\n",
       "      <td>0.903430</td>\n",
       "      <td>4.418314</td>\n",
       "      <td>2.202457</td>\n",
       "      <td>2.384530</td>\n",
       "      <td>1.282864</td>\n",
       "      <td>-0.437195</td>\n",
       "      <td>-0.633742</td>\n",
       "      <td>0.861229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026072</th>\n",
       "      <td>8.695135</td>\n",
       "      <td>-3.834220</td>\n",
       "      <td>-2.078501</td>\n",
       "      <td>2.316255</td>\n",
       "      <td>-0.579175</td>\n",
       "      <td>-1.012689</td>\n",
       "      <td>2.724683</td>\n",
       "      <td>0.646925</td>\n",
       "      <td>0.066713</td>\n",
       "      <td>-1.181772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026083</th>\n",
       "      <td>1.622089</td>\n",
       "      <td>0.356023</td>\n",
       "      <td>-1.366311</td>\n",
       "      <td>-1.810328</td>\n",
       "      <td>-0.948143</td>\n",
       "      <td>0.265917</td>\n",
       "      <td>0.993383</td>\n",
       "      <td>-0.537539</td>\n",
       "      <td>-0.051097</td>\n",
       "      <td>0.443448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026179</th>\n",
       "      <td>1.174178</td>\n",
       "      <td>-1.845445</td>\n",
       "      <td>-4.586893</td>\n",
       "      <td>-4.290789</td>\n",
       "      <td>2.636322</td>\n",
       "      <td>2.751485</td>\n",
       "      <td>-0.067389</td>\n",
       "      <td>0.927045</td>\n",
       "      <td>-0.518355</td>\n",
       "      <td>2.040406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86195 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pca_0     pca_1     pca_2     pca_3     pca_4     pca_5     pca_6   \n",
       "eid                                                                             \n",
       "1000066 -2.252839  3.066601 -2.913292 -2.328768  1.500444  1.818484 -1.092669  \\\n",
       "1000156 -5.963784  0.325908 -1.809769  2.433903 -0.624344  0.911276 -0.220119   \n",
       "1000199 -4.968379 -0.170561 -0.363203  1.222055  2.232448 -0.122127 -1.113042   \n",
       "1000301  6.130622  1.322871  1.488849 -0.134390  1.098978  0.586573 -3.117746   \n",
       "1000378 -4.354016 -0.258280 -2.338870 -0.358884  3.314417  1.889463 -0.674396   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "6025959  2.996337 -0.728765  2.447221 -1.584065 -2.570893 -0.322580 -1.135632   \n",
       "6026028  4.927389  3.239777  0.903430  4.418314  2.202457  2.384530  1.282864   \n",
       "6026072  8.695135 -3.834220 -2.078501  2.316255 -0.579175 -1.012689  2.724683   \n",
       "6026083  1.622089  0.356023 -1.366311 -1.810328 -0.948143  0.265917  0.993383   \n",
       "6026179  1.174178 -1.845445 -4.586893 -4.290789  2.636322  2.751485 -0.067389   \n",
       "\n",
       "            pca_7     pca_8     pca_9  \n",
       "eid                                    \n",
       "1000066 -1.270074 -1.512550  3.528600  \n",
       "1000156  0.139989 -0.655710  1.087488  \n",
       "1000199 -0.046429 -1.952182  0.913763  \n",
       "1000301 -1.187186  0.740730 -0.114611  \n",
       "1000378  2.056707 -1.619832 -3.547954  \n",
       "...           ...       ...       ...  \n",
       "6025959  0.223566 -0.775059 -1.589258  \n",
       "6026028 -0.437195 -0.633742  0.861229  \n",
       "6026072  0.646925  0.066713 -1.181772  \n",
       "6026083 -0.537539 -0.051097  0.443448  \n",
       "6026179  0.927045 -0.518355  2.040406  \n",
       "\n",
       "[86195 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collapsed = df.reset_index().groupby('eid').last()\n",
    "df_collapsed = df_collapsed.drop(['fid', 'instance_id', 'array_id'], axis=1)\n",
    "df_collapsed.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df_collapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(embeddings: torch.Tensor, labels: torch.Tensor, device) -> nn.Module:\n",
    "    # Train a linear model\n",
    "    linear_model = nn.Linear(embeddings.shape[1], len(torch.unique(labels))).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr=3e-4)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(5000):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = linear_model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return linear_model\n",
    "\n",
    "def plot_roc_curve(labels: List[int], scores: List[float]):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train a linear model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_linear_model\u001b[49m(embeddings_tensor, labels_tensor, device)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate scores using the linear model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m scores \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(linear_model(embeddings_tensor))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train a linear model\n",
    "linear_model = train_linear_model(embeddings_tensor, labels_tensor, device)\n",
    "\n",
    "# Calculate scores using the linear model\n",
    "scores = nn.functional.softmax(linear_model(embeddings_tensor)).detach().cpu().numpy()\n",
    "# Plot ROC curve for each class\n",
    "for class_label in torch.unique(labels_tensor):\n",
    "    class_scores = scores[:, class_label]\n",
    "    class_labels = [1 if label == class_label else 0 for label in labels_tensor]\n",
    "    plot_roc_curve(class_labels, class_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation - Pretrained SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'problem': 'eval',\n",
    "    'eval_only': 'true',\n",
    "    'iters': 1,\n",
    "    'archs': 'linear'\n",
    "    'data': --problem eval --eval_only true --iters 1 --arch linear --data imagenet\n",
    "}\n",
    "cmd\n",
    "os.system('python ~/OCT_Feature_Extractor/externals/simclr/train.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-deepMMR]",
   "language": "python",
   "name": "conda-env-anaconda-deepMMR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
