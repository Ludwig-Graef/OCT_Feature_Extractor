{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Tuple, List, Tuple, Optional\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import subprocess as sp\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torchvision.datasets import DatasetFolder, ImageFolder\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA as Sklearn_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from fundus_extractor.utils.general import imshow, normalize_image\n",
    "from fundus_extractor.utils.datasets import Fundus_Left_Right_Combined_Dataset\n",
    "from fundus_extractor.models import pretrained_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit_slurm_array(training_save_dir: str, cmds: list, memory_in_gb: int, cores: int, gpu: bool, queue: str,\n",
    "                       n_parallel_jobs: int, **kwargs) -> None:\n",
    "    os.makedirs(training_save_dir, exist_ok=True)\n",
    "\n",
    "    for ii, cmd in enumerate(cmds):\n",
    "        job_dir = os.path.join(training_save_dir, f'run_{ii}') \n",
    "        os.makedirs(job_dir, exist_ok=True)\n",
    "        job_file = f'{job_dir}/job.sh'\n",
    "        out_file = f'{job_dir}/out.txt'\n",
    "        err_file = f'{job_dir}/err.txt'\n",
    "        with open(job_file, 'w') as handle:\n",
    "            handle.writelines(\"#!/bin/bash\\n\")\n",
    "            handle.writelines(f\"source $HOME/.bashrc\\n\")\n",
    "            handle.writelines(f\"conda activate deepMMR\\n\")\n",
    "            handle.writelines(f'{cmd} >> {out_file} 2>> {err_file}\\n\\n')\n",
    "        os.chmod(job_file, 0o777)\n",
    "        \n",
    "    job_file = os.path.join(training_save_dir, 'job.sh')\n",
    "    out_file = os.path.join(training_save_dir, 'out.txt')\n",
    "    err_file = os.path.join(training_save_dir, 'err.txt')\n",
    "    \n",
    "    with open(job_file, 'w') as handle:\n",
    "        handle.writelines(\"#!/bin/bash\\n\")\n",
    "\n",
    "        handle.writelines('#SBATCH -J MMR_Job_Array\\n')\n",
    "        handle.writelines(f'#SBATCH -o {out_file}\\n')\n",
    "        handle.writelines(f'#SBATCH -e {err_file}\\n')\n",
    "\n",
    "        handle.writelines('#SBATCH -t 24:00:00\\n')\n",
    "        handle.writelines(f'#SBATCH -p {queue}\\n')\n",
    "        handle.writelines(f'#SBATCH -c {cores}\\n')\n",
    "        handle.writelines(f'#SBATCH --mem={memory_in_gb}GB\\n')\n",
    "        handle.writelines(f'#SBATCH --exclude=ouga[16-17]\\n')\n",
    "        if gpu is True:\n",
    "            handle.writelines('#SBATCH --gres=gpu:1\\n')\n",
    "        handle.writelines(f'#SBATCH -a 0-{len(cmds)-1}%{n_parallel_jobs}\\n')\n",
    "\n",
    "        handle.writelines(f'cd {training_save_dir}\\n')\n",
    "        handle.writelines('./run_${SLURM_ARRAY_TASK_ID}/job.sh\\n')\n",
    "\n",
    "    sp.Popen([\"sbatch\", job_file], stdout=sp.PIPE, stderr=sp.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/s/project/deepMMR/data/fundus/processed/left'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/s/project/deepMMR/data/fundus/processed/left\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m dataset_left \u001b[38;5;241m=\u001b[39m \u001b[43mFundus_Left_Right_Combined_Dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train_dataloader_left \u001b[38;5;241m=\u001b[39m DataLoader(dataset_left, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m      5\u001b[0m dataset_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/s/project/deepMMR/data/fundus/processed/right\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/data/nasif12/home_if12/graef/OCT_Feature_Extractor/fundus_extractor/utils/datasets.py:21\u001b[0m, in \u001b[0;36mFundus_Left_Right_Combined_Dataset.__init__\u001b[0;34m(self, root, loader, transform)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, root: \u001b[38;5;28mstr\u001b[39m, loader: Callable[[\u001b[38;5;28mstr\u001b[39m], Any], transform: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/datasets/folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/datasets/folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/datasets/folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/s/project/deepMMR/data/fundus/processed/left'"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/s/project/deepMMR/data/fundus/processed/left'\n",
    "dataset_left = Fundus_Left_Right_Combined_Dataset(dataset_dir, loader=lambda x: normalize_image(torchvision.io.read_image(x)))\n",
    "train_dataloader_left = DataLoader(dataset_left, batch_size=1024)\n",
    "\n",
    "dataset_dir = '/s/project/deepMMR/data/fundus/processed/right'\n",
    "dataset_right = Fundus_Left_Right_Combined_Dataset(dataset_dir, loader=lambda x: normalize_image(torchvision.io.read_image(x)))\n",
    "train_dataloader_right = DataLoader(dataset_right, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation - transferGWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path_left = '/data/ouga/home/ag_gagneur/graef/tmp/retinas_left.csv'\n",
    "save_path_right = '/data/ouga/home/ag_gagneur/graef/tmp/retinas_right.csv'\n",
    "save_path = '/data/ouga/home/ag_gagneur/graef/tmp/retinas.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IID</th>\n",
       "      <th>path</th>\n",
       "      <th>instance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1178447_0_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/l...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1186186_0_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/l...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1181999_0_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/l...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1178854_0_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/l...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1173877_0_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/l...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178270</th>\n",
       "      <td>4607590_0_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/r...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178271</th>\n",
       "      <td>4614645_1_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/r...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178272</th>\n",
       "      <td>4607023_0_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/r...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178273</th>\n",
       "      <td>4623261_1_0</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/r...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178274</th>\n",
       "      <td>4607589_2_1</td>\n",
       "      <td>/s/project/deepMMR/data/fundus/processed_v_1/r...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175152 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                IID                                               path   \n",
       "0       1178447_0_0  /s/project/deepMMR/data/fundus/processed_v_1/l...  \\\n",
       "1       1186186_0_0  /s/project/deepMMR/data/fundus/processed_v_1/l...   \n",
       "2       1181999_0_0  /s/project/deepMMR/data/fundus/processed_v_1/l...   \n",
       "3       1178854_0_0  /s/project/deepMMR/data/fundus/processed_v_1/l...   \n",
       "4       1173877_0_0  /s/project/deepMMR/data/fundus/processed_v_1/l...   \n",
       "...             ...                                                ...   \n",
       "178270  4607590_0_0  /s/project/deepMMR/data/fundus/processed_v_1/r...   \n",
       "178271  4614645_1_0  /s/project/deepMMR/data/fundus/processed_v_1/r...   \n",
       "178272  4607023_0_0  /s/project/deepMMR/data/fundus/processed_v_1/r...   \n",
       "178273  4623261_1_0  /s/project/deepMMR/data/fundus/processed_v_1/r...   \n",
       "178274  4607589_2_1  /s/project/deepMMR/data/fundus/processed_v_1/r...   \n",
       "\n",
       "       instance  \n",
       "0          left  \n",
       "1          left  \n",
       "2          left  \n",
       "3          left  \n",
       "4          left  \n",
       "...         ...  \n",
       "178270    right  \n",
       "178271    right  \n",
       "178272    right  \n",
       "178273    right  \n",
       "178274    right  \n",
       "\n",
       "[175152 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = defaultdict(list)\n",
    "\n",
    "images_dir_left = '/s/project/deepMMR/data/fundus/processed_v_1/left/'\n",
    "for sub_dir in os.listdir(images_dir_left):\n",
    "    for file in os.listdir(os.path.join(images_dir_left, sub_dir)):\n",
    "        eid, _, instance_id, group_id = file.split('.')[0].split('_')\n",
    "        data['IID'].append('_'.join([eid, instance_id, group_id]))\n",
    "        data['path'].append(os.path.join(images_dir_left, sub_dir, file))\n",
    "        data['instance'].append('left')\n",
    "\n",
    "images_dir_right = '/s/project/deepMMR/data/fundus/processed_v_1/right/'\n",
    "for sub_dir in os.listdir(images_dir_right):\n",
    "    for file in os.listdir(os.path.join(images_dir_right, sub_dir)):\n",
    "        eid, _, instance_id, group_id = file.split('.')[0].split('_')\n",
    "        data['IID'].append('_'.join([eid, instance_id, group_id]))\n",
    "        data['path'].append(os.path.join(images_dir_right, sub_dir, file))\n",
    "        data['instance'].append('right')\n",
    "\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df = data_df.groupby('IID').filter(lambda x: len(x) == 2)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmds = []\n",
    "for ii, indices in enumerate(np.array_split(np.unique(data_df['IID']), 8)):\n",
    "    save_dir = f'/data/ouga/home/ag_gagneur/graef/tmp/slurm/img_extraction/run_{ii}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    indices_path = os.path.join(save_dir, 'retinas.csv')\n",
    "    data_df[data_df['IID'].isin(indices)].to_csv(indices_path, sep=',', index=None)\n",
    "    cmd = f'python /data/ouga/home/ag_gagneur/graef/Programs/transferGWAS/feature_condensation/feature_condensation.py {indices_path} {save_dir} \\\n",
    "                    --tfms tta \\\n",
    "                    --dev cuda:0 \\\n",
    "                    --n_pcs 256 \\\n",
    "                    --model resnet50 \\\n",
    "                    --pretraining imagenet \\\n",
    "                    --layer L2 L3 L4'\n",
    "    cmds.append(cmd)\n",
    "submit_slurm_array('/data/ouga/home/ag_gagneur/graef/tmp/slurm/img_extraction', cmds, 32, 16, True, 'standard', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>eid</th>\n",
       "      <th>instance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000066_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000156_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000199_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000378_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000424_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47854</th>\n",
       "      <td>47854</td>\n",
       "      <td>6002837_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47855</th>\n",
       "      <td>47855</td>\n",
       "      <td>6003318_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47856</th>\n",
       "      <td>47856</td>\n",
       "      <td>6003414_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47857</th>\n",
       "      <td>47857</td>\n",
       "      <td>6003874_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47858</th>\n",
       "      <td>47858</td>\n",
       "      <td>6003930_0_0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47859 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          eid instance\n",
       "0               0  1000066_0_0      0_0\n",
       "1               1  1000156_0_0      0_0\n",
       "2               2  1000199_0_0      0_0\n",
       "3               3  1000378_0_0      0_0\n",
       "4               4  1000424_0_0      0_0\n",
       "...           ...          ...      ...\n",
       "47854       47854  6002837_0_0      0_0\n",
       "47855       47855  6003318_0_0      0_0\n",
       "47856       47856  6003414_0_0      0_0\n",
       "47857       47857  6003874_0_0      0_0\n",
       "47858       47858  6003930_0_0      0_0\n",
       "\n",
       "[47859 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_eids_df = pd.read_csv('/s/project/deepMMR/data/fundus/processed_transferGWAS/good_eids.tsv', sep='\\t')\n",
    "good_eids_df['eid'] = good_eids_df['eid'].astype('str') + '_' + good_eids_df['instance'].astype('str')\n",
    "good_eids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:19, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10947, 32768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:36, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10947, 32768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:54, 17.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10947, 32768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:10, 17.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10947, 32768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:26, 16.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10947, 32768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:42, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10947, 32768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:59, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10947, 32768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:16, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10947, 32768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "slurm_dir = '/data/ouga/home/ag_gagneur/graef/tmp/slurm/img_extraction'\n",
    "dfs = []\n",
    "for folder_name in tqdm(filter(lambda x: x.startswith('run_'), os.listdir(slurm_dir))):\n",
    "    df = pd.read_parquet(os.path.join(slurm_dir, folder_name, 'resnet50_imagenet_L4.parquet'))\n",
    "    print(df.shape)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for good images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_32758</th>\n",
       "      <th>feature_32759</th>\n",
       "      <th>feature_32760</th>\n",
       "      <th>feature_32761</th>\n",
       "      <th>feature_32762</th>\n",
       "      <th>feature_32763</th>\n",
       "      <th>feature_32764</th>\n",
       "      <th>feature_32765</th>\n",
       "      <th>feature_32766</th>\n",
       "      <th>feature_32767</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4746235</th>\n",
       "      <td>-0.003206</td>\n",
       "      <td>-0.039855</td>\n",
       "      <td>-0.008334</td>\n",
       "      <td>-0.010823</td>\n",
       "      <td>-0.016105</td>\n",
       "      <td>-0.015539</td>\n",
       "      <td>-0.016325</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>-0.009391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.011218</td>\n",
       "      <td>-0.017621</td>\n",
       "      <td>-0.010564</td>\n",
       "      <td>-0.033377</td>\n",
       "      <td>-0.012606</td>\n",
       "      <td>-0.021626</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>-0.006857</td>\n",
       "      <td>-0.003686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746244</th>\n",
       "      <td>-0.007086</td>\n",
       "      <td>-0.037163</td>\n",
       "      <td>-0.011511</td>\n",
       "      <td>-0.010331</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>-0.009989</td>\n",
       "      <td>-0.017827</td>\n",
       "      <td>-0.014827</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009360</td>\n",
       "      <td>-0.013854</td>\n",
       "      <td>-0.013611</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>-0.030194</td>\n",
       "      <td>-0.010197</td>\n",
       "      <td>-0.024628</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>-0.011893</td>\n",
       "      <td>-0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746283</th>\n",
       "      <td>-0.014682</td>\n",
       "      <td>-0.047901</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>-0.015985</td>\n",
       "      <td>-0.005365</td>\n",
       "      <td>-0.015759</td>\n",
       "      <td>-0.004806</td>\n",
       "      <td>-0.013369</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006534</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>-0.016171</td>\n",
       "      <td>-0.016500</td>\n",
       "      <td>-0.032435</td>\n",
       "      <td>-0.010747</td>\n",
       "      <td>-0.013824</td>\n",
       "      <td>-0.002733</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>-0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746340</th>\n",
       "      <td>-0.014750</td>\n",
       "      <td>-0.036411</td>\n",
       "      <td>-0.012396</td>\n",
       "      <td>-0.020943</td>\n",
       "      <td>-0.007158</td>\n",
       "      <td>-0.014859</td>\n",
       "      <td>-0.017481</td>\n",
       "      <td>-0.010266</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>-0.003396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>-0.020304</td>\n",
       "      <td>-0.019081</td>\n",
       "      <td>-0.010744</td>\n",
       "      <td>-0.036250</td>\n",
       "      <td>-0.011738</td>\n",
       "      <td>-0.019442</td>\n",
       "      <td>-0.002293</td>\n",
       "      <td>-0.002074</td>\n",
       "      <td>-0.006216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746523</th>\n",
       "      <td>-0.010752</td>\n",
       "      <td>-0.035019</td>\n",
       "      <td>-0.013908</td>\n",
       "      <td>-0.016347</td>\n",
       "      <td>-0.008835</td>\n",
       "      <td>-0.010481</td>\n",
       "      <td>-0.009424</td>\n",
       "      <td>-0.001223</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>-0.013628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006420</td>\n",
       "      <td>-0.007171</td>\n",
       "      <td>-0.014903</td>\n",
       "      <td>-0.016275</td>\n",
       "      <td>-0.036366</td>\n",
       "      <td>-0.010654</td>\n",
       "      <td>-0.013503</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>-0.005925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745681</th>\n",
       "      <td>-0.009270</td>\n",
       "      <td>-0.044545</td>\n",
       "      <td>-0.012166</td>\n",
       "      <td>-0.016307</td>\n",
       "      <td>-0.007294</td>\n",
       "      <td>-0.010210</td>\n",
       "      <td>-0.015846</td>\n",
       "      <td>-0.005875</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>-0.007127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006310</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.013078</td>\n",
       "      <td>-0.017825</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>-0.011700</td>\n",
       "      <td>-0.022435</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>-0.003910</td>\n",
       "      <td>-0.003230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745711</th>\n",
       "      <td>-0.008744</td>\n",
       "      <td>-0.033774</td>\n",
       "      <td>-0.008761</td>\n",
       "      <td>-0.023654</td>\n",
       "      <td>-0.003511</td>\n",
       "      <td>-0.020428</td>\n",
       "      <td>-0.023930</td>\n",
       "      <td>-0.006611</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>-0.007331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011737</td>\n",
       "      <td>-0.000948</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>-0.018848</td>\n",
       "      <td>-0.029474</td>\n",
       "      <td>-0.009620</td>\n",
       "      <td>-0.018838</td>\n",
       "      <td>-0.004287</td>\n",
       "      <td>-0.006817</td>\n",
       "      <td>-0.004656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745817</th>\n",
       "      <td>-0.010285</td>\n",
       "      <td>-0.047463</td>\n",
       "      <td>-0.010427</td>\n",
       "      <td>-0.017209</td>\n",
       "      <td>-0.014156</td>\n",
       "      <td>-0.009614</td>\n",
       "      <td>-0.007318</td>\n",
       "      <td>-0.009890</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>-0.004971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>-0.015734</td>\n",
       "      <td>-0.013198</td>\n",
       "      <td>-0.011969</td>\n",
       "      <td>-0.039542</td>\n",
       "      <td>-0.009397</td>\n",
       "      <td>-0.022899</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.005407</td>\n",
       "      <td>-0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745852</th>\n",
       "      <td>-0.009231</td>\n",
       "      <td>-0.037722</td>\n",
       "      <td>-0.007721</td>\n",
       "      <td>-0.019867</td>\n",
       "      <td>-0.006730</td>\n",
       "      <td>-0.023671</td>\n",
       "      <td>-0.021419</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007135</td>\n",
       "      <td>-0.014455</td>\n",
       "      <td>-0.020018</td>\n",
       "      <td>-0.014558</td>\n",
       "      <td>-0.028342</td>\n",
       "      <td>-0.009949</td>\n",
       "      <td>-0.020664</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>-0.005441</td>\n",
       "      <td>-0.004853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745965</th>\n",
       "      <td>-0.014556</td>\n",
       "      <td>-0.034809</td>\n",
       "      <td>-0.008685</td>\n",
       "      <td>-0.020476</td>\n",
       "      <td>-0.007206</td>\n",
       "      <td>-0.021166</td>\n",
       "      <td>-0.007147</td>\n",
       "      <td>-0.016998</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>-0.017246</td>\n",
       "      <td>-0.017680</td>\n",
       "      <td>-0.039592</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>-0.018707</td>\n",
       "      <td>-0.003381</td>\n",
       "      <td>-0.012522</td>\n",
       "      <td>-0.009326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47756 rows × 32768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2  feature_3  feature_4  feature_5   \n",
       "eid                                                                         \n",
       "4746235  -0.003206  -0.039855  -0.008334  -0.010823  -0.016105  -0.015539  \\\n",
       "4746244  -0.007086  -0.037163  -0.011511  -0.010331  -0.015124  -0.009989   \n",
       "4746283  -0.014682  -0.047901  -0.008772  -0.015985  -0.005365  -0.015759   \n",
       "4746340  -0.014750  -0.036411  -0.012396  -0.020943  -0.007158  -0.014859   \n",
       "4746523  -0.010752  -0.035019  -0.013908  -0.016347  -0.008835  -0.010481   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "4745681  -0.009270  -0.044545  -0.012166  -0.016307  -0.007294  -0.010210   \n",
       "4745711  -0.008744  -0.033774  -0.008761  -0.023654  -0.003511  -0.020428   \n",
       "4745817  -0.010285  -0.047463  -0.010427  -0.017209  -0.014156  -0.009614   \n",
       "4745852  -0.009231  -0.037722  -0.007721  -0.019867  -0.006730  -0.023671   \n",
       "4745965  -0.014556  -0.034809  -0.008685  -0.020476  -0.007206  -0.021166   \n",
       "\n",
       "         feature_6  feature_7  feature_8  feature_9  ...  feature_32758   \n",
       "eid                                                  ...                  \n",
       "4746235  -0.016325   0.002699  -0.001988  -0.009391  ...       0.000034  \\\n",
       "4746244  -0.017827  -0.014827   0.004621  -0.007907  ...      -0.009360   \n",
       "4746283  -0.004806  -0.013369   0.004391  -0.003049  ...      -0.006534   \n",
       "4746340  -0.017481  -0.010266   0.001232  -0.003396  ...      -0.001127   \n",
       "4746523  -0.009424  -0.001223   0.007449  -0.013628  ...      -0.006420   \n",
       "...            ...        ...        ...        ...  ...            ...   \n",
       "4745681  -0.015846  -0.005875   0.001209  -0.007127  ...      -0.006310   \n",
       "4745711  -0.023930  -0.006611   0.007818  -0.007331  ...      -0.011737   \n",
       "4745817  -0.007318  -0.009890   0.006406  -0.004971  ...      -0.000620   \n",
       "4745852  -0.021419   0.002696   0.011576  -0.006329  ...      -0.007135   \n",
       "4745965  -0.007147  -0.016998   0.010165   0.000137  ...      -0.008339   \n",
       "\n",
       "         feature_32759  feature_32760  feature_32761  feature_32762   \n",
       "eid                                                                   \n",
       "4746235      -0.011218      -0.017621      -0.010564      -0.033377  \\\n",
       "4746244      -0.013854      -0.013611      -0.006036      -0.030194   \n",
       "4746283      -0.012249      -0.016171      -0.016500      -0.032435   \n",
       "4746340      -0.020304      -0.019081      -0.010744      -0.036250   \n",
       "4746523      -0.007171      -0.014903      -0.016275      -0.036366   \n",
       "...                ...            ...            ...            ...   \n",
       "4745681      -0.000156      -0.013078      -0.017825      -0.032487   \n",
       "4745711      -0.000948      -0.025162      -0.018848      -0.029474   \n",
       "4745817      -0.015734      -0.013198      -0.011969      -0.039542   \n",
       "4745852      -0.014455      -0.020018      -0.014558      -0.028342   \n",
       "4745965      -0.004723      -0.017246      -0.017680      -0.039592   \n",
       "\n",
       "         feature_32763  feature_32764  feature_32765  feature_32766   \n",
       "eid                                                                   \n",
       "4746235      -0.012606      -0.021626       0.001789      -0.006857  \\\n",
       "4746244      -0.010197      -0.024628       0.002278      -0.011893   \n",
       "4746283      -0.010747      -0.013824      -0.002733      -0.010527   \n",
       "4746340      -0.011738      -0.019442      -0.002293      -0.002074   \n",
       "4746523      -0.010654      -0.013503       0.002626      -0.018750   \n",
       "...                ...            ...            ...            ...   \n",
       "4745681      -0.011700      -0.022435      -0.000638      -0.003910   \n",
       "4745711      -0.009620      -0.018838      -0.004287      -0.006817   \n",
       "4745817      -0.009397      -0.022899      -0.000129      -0.005407   \n",
       "4745852      -0.009949      -0.020664       0.001331      -0.005441   \n",
       "4745965      -0.009018      -0.018707      -0.003381      -0.012522   \n",
       "\n",
       "         feature_32767  \n",
       "eid                     \n",
       "4746235      -0.003686  \n",
       "4746244      -0.001478  \n",
       "4746283      -0.004800  \n",
       "4746340      -0.006216  \n",
       "4746523      -0.005925  \n",
       "...                ...  \n",
       "4745681      -0.003230  \n",
       "4745711      -0.004656  \n",
       "4745817      -0.001750  \n",
       "4745852      -0.004853  \n",
       "4745965      -0.009326  \n",
       "\n",
       "[47756 rows x 32768 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Filtering for good images')\n",
    "df = df[df.index.isin(good_eids_df['eid'])]\n",
    "\n",
    "df.index = df.index.str.split('_').str[0]\n",
    "df.index.names = ['eid']\n",
    "\n",
    "duplicates = df.index.duplicated(keep='first')\n",
    "df = df[~duplicates]\n",
    "\n",
    "df.columns = [f'feature_{ii}' for ii in range(df.shape[1])]\n",
    "\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/transferGWAS.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = Sklearn_PCA(n_components=256)\n",
    "    \n",
    "transformed_data = pd.DataFrame(pca.fit_transform(df), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_246</th>\n",
       "      <th>pca_247</th>\n",
       "      <th>pca_248</th>\n",
       "      <th>pca_249</th>\n",
       "      <th>pca_250</th>\n",
       "      <th>pca_251</th>\n",
       "      <th>pca_252</th>\n",
       "      <th>pca_253</th>\n",
       "      <th>pca_254</th>\n",
       "      <th>pca_255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4746235</th>\n",
       "      <td>-0.020120</td>\n",
       "      <td>0.145689</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>-0.226854</td>\n",
       "      <td>-0.393981</td>\n",
       "      <td>-0.185676</td>\n",
       "      <td>-0.199469</td>\n",
       "      <td>0.059713</td>\n",
       "      <td>0.074342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>-0.034215</td>\n",
       "      <td>-0.020861</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>0.018578</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.022518</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>-0.003797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746244</th>\n",
       "      <td>-0.188309</td>\n",
       "      <td>0.157758</td>\n",
       "      <td>-0.009927</td>\n",
       "      <td>-0.087749</td>\n",
       "      <td>-0.218655</td>\n",
       "      <td>-0.036896</td>\n",
       "      <td>0.153772</td>\n",
       "      <td>-0.088752</td>\n",
       "      <td>0.298271</td>\n",
       "      <td>0.183549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029813</td>\n",
       "      <td>0.017334</td>\n",
       "      <td>0.024025</td>\n",
       "      <td>0.026061</td>\n",
       "      <td>0.011953</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.020462</td>\n",
       "      <td>-0.012744</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>-0.009807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746283</th>\n",
       "      <td>-0.040014</td>\n",
       "      <td>-0.001831</td>\n",
       "      <td>0.170681</td>\n",
       "      <td>0.129425</td>\n",
       "      <td>-0.144264</td>\n",
       "      <td>0.098919</td>\n",
       "      <td>0.152216</td>\n",
       "      <td>-0.009691</td>\n",
       "      <td>-0.004499</td>\n",
       "      <td>-0.210789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021833</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.020713</td>\n",
       "      <td>0.016531</td>\n",
       "      <td>0.013741</td>\n",
       "      <td>-0.017557</td>\n",
       "      <td>-0.000670</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.010935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746340</th>\n",
       "      <td>0.316499</td>\n",
       "      <td>-0.402730</td>\n",
       "      <td>-0.241877</td>\n",
       "      <td>-0.123452</td>\n",
       "      <td>-0.160672</td>\n",
       "      <td>0.021331</td>\n",
       "      <td>-0.089546</td>\n",
       "      <td>-0.020574</td>\n",
       "      <td>-0.047664</td>\n",
       "      <td>-0.021314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005854</td>\n",
       "      <td>-0.004711</td>\n",
       "      <td>-0.025347</td>\n",
       "      <td>0.018861</td>\n",
       "      <td>-0.004173</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>-0.003183</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>-0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746523</th>\n",
       "      <td>0.439099</td>\n",
       "      <td>-0.110558</td>\n",
       "      <td>0.365479</td>\n",
       "      <td>-0.096309</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>0.128773</td>\n",
       "      <td>0.091877</td>\n",
       "      <td>-0.063077</td>\n",
       "      <td>0.100898</td>\n",
       "      <td>-0.005770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014531</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>0.017534</td>\n",
       "      <td>-0.001634</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>-0.009190</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>-0.008261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745681</th>\n",
       "      <td>0.177313</td>\n",
       "      <td>0.267705</td>\n",
       "      <td>0.174638</td>\n",
       "      <td>-0.086352</td>\n",
       "      <td>-0.086408</td>\n",
       "      <td>-0.085933</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>-0.051453</td>\n",
       "      <td>0.157691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>-0.001410</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>-0.007033</td>\n",
       "      <td>-0.002412</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>-0.016497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745711</th>\n",
       "      <td>0.440370</td>\n",
       "      <td>0.191072</td>\n",
       "      <td>-0.107405</td>\n",
       "      <td>-0.084283</td>\n",
       "      <td>0.240803</td>\n",
       "      <td>-0.207348</td>\n",
       "      <td>0.153951</td>\n",
       "      <td>0.068401</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.212495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>-0.015865</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>-0.005555</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>0.025287</td>\n",
       "      <td>0.004618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745817</th>\n",
       "      <td>-0.115985</td>\n",
       "      <td>-0.160457</td>\n",
       "      <td>0.253863</td>\n",
       "      <td>0.128876</td>\n",
       "      <td>0.087355</td>\n",
       "      <td>-0.027015</td>\n",
       "      <td>-0.408453</td>\n",
       "      <td>-0.016170</td>\n",
       "      <td>0.070934</td>\n",
       "      <td>-0.106881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012185</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>-0.017653</td>\n",
       "      <td>0.035389</td>\n",
       "      <td>-0.010735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745852</th>\n",
       "      <td>0.495734</td>\n",
       "      <td>0.088478</td>\n",
       "      <td>-0.202750</td>\n",
       "      <td>-0.371185</td>\n",
       "      <td>0.156027</td>\n",
       "      <td>-0.315737</td>\n",
       "      <td>0.178060</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>-0.058676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>-0.008488</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.020433</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>-0.022524</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745965</th>\n",
       "      <td>0.090136</td>\n",
       "      <td>-0.103349</td>\n",
       "      <td>-0.048638</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>-0.172398</td>\n",
       "      <td>0.184839</td>\n",
       "      <td>-0.032668</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>-0.094816</td>\n",
       "      <td>-0.104093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>-0.019039</td>\n",
       "      <td>-0.025105</td>\n",
       "      <td>0.017602</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.022455</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.017989</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.009215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47756 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pca_0     pca_1     pca_2     pca_3     pca_4     pca_5     pca_6   \n",
       "eid                                                                             \n",
       "4746235 -0.020120  0.145689  0.015448  0.000227 -0.226854 -0.393981 -0.185676  \\\n",
       "4746244 -0.188309  0.157758 -0.009927 -0.087749 -0.218655 -0.036896  0.153772   \n",
       "4746283 -0.040014 -0.001831  0.170681  0.129425 -0.144264  0.098919  0.152216   \n",
       "4746340  0.316499 -0.402730 -0.241877 -0.123452 -0.160672  0.021331 -0.089546   \n",
       "4746523  0.439099 -0.110558  0.365479 -0.096309  0.076627  0.128773  0.091877   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "4745681  0.177313  0.267705  0.174638 -0.086352 -0.086408 -0.085933  0.043768   \n",
       "4745711  0.440370  0.191072 -0.107405 -0.084283  0.240803 -0.207348  0.153951   \n",
       "4745817 -0.115985 -0.160457  0.253863  0.128876  0.087355 -0.027015 -0.408453   \n",
       "4745852  0.495734  0.088478 -0.202750 -0.371185  0.156027 -0.315737  0.178060   \n",
       "4745965  0.090136 -0.103349 -0.048638  0.013463 -0.172398  0.184839 -0.032668   \n",
       "\n",
       "            pca_7     pca_8     pca_9  ...   pca_246   pca_247   pca_248   \n",
       "eid                                    ...                                 \n",
       "4746235 -0.199469  0.059713  0.074342  ...  0.007815 -0.034215 -0.020861  \\\n",
       "4746244 -0.088752  0.298271  0.183549  ...  0.029813  0.017334  0.024025   \n",
       "4746283 -0.009691 -0.004499 -0.210789  ... -0.021833  0.001041  0.020713   \n",
       "4746340 -0.020574 -0.047664 -0.021314  ... -0.005854 -0.004711 -0.025347   \n",
       "4746523 -0.063077  0.100898 -0.005770  ... -0.014531  0.018834  0.017534   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "4745681  0.017420 -0.051453  0.157691  ...  0.015596  0.006483  0.006233   \n",
       "4745711  0.068401  0.001756  0.212495  ...  0.008221  0.012764 -0.015865   \n",
       "4745817 -0.016170  0.070934 -0.106881  ... -0.012185  0.022688  0.006188   \n",
       "4745852  0.004047  0.032492 -0.058676  ...  0.001475 -0.008488  0.018248   \n",
       "4745965  0.026633 -0.094816 -0.104093  ...  0.000674 -0.019039 -0.025105   \n",
       "\n",
       "          pca_249   pca_250   pca_251   pca_252   pca_253   pca_254   pca_255  \n",
       "eid                                                                            \n",
       "4746235  0.004830 -0.003564  0.018578  0.002755  0.022518  0.004137 -0.003797  \n",
       "4746244  0.026061  0.011953  0.002740  0.020462 -0.012744  0.003718 -0.009807  \n",
       "4746283  0.016531  0.013741 -0.017557 -0.000670  0.014847  0.001710  0.010935  \n",
       "4746340  0.018861 -0.004173 -0.016727  0.015462 -0.003183  0.023903 -0.000009  \n",
       "4746523 -0.001634  0.003142  0.016105 -0.009190  0.010184  0.011138 -0.008261  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "4745681 -0.001410  0.009410  0.003454 -0.007033 -0.002412  0.005104 -0.016497  \n",
       "4745711  0.003843 -0.005555  0.005481  0.009734  0.011838  0.025287  0.004618  \n",
       "4745817 -0.018488  0.000872 -0.000325  0.001152 -0.017653  0.035389 -0.010735  \n",
       "4745852  0.029779  0.030098  0.006795  0.020433  0.010394 -0.022524  0.005185  \n",
       "4745965  0.017602  0.002007  0.022455 -0.000116  0.017989  0.016695  0.009215  \n",
       "\n",
       "[47756 rows x 256 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.columns = [f'pca_{ii}' for ii in range(len(transformed_data.columns))]\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_data.iloc[:, range(10)].to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/transferGWAS_pca_10.parquet')\n",
    "transformed_data.iloc[:, range(20)].to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/transferGWAS_pca_20.parquet')\n",
    "transformed_data.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/transferGWAS_pca_256.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Evaluation - Pretrained ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Process inputs: 100%|██████████| 87/87 [57:44<00:00, 39.82s/it] \n",
      "Process inputs:  48%|████▊     | 42/88 [30:21<32:52, 42.89s/it] "
     ]
    }
   ],
   "source": [
    "model = pretrained_pca.ImageEncoder('resnet50').to(device)\n",
    "features_left, labels_left = pretrained_pca.extract_features(model, train_dataloader_left, device)\n",
    "features_right, labels_right = pretrained_pca.extract_features(model, train_dataloader_right, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_left, features_left)}\n",
    "data_right = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_right, features_right)}\n",
    "data = {label: np.concatenate([feature_left, data_right[label]]) for (label, feature_left) in data_left.items() if label in data_right.keys()}\n",
    "pca = Sklearn_PCA(n_components=128) # 10\n",
    "embeddings = pca.fit_transform(np.stack(data.values()))\n",
    "minimum_variance_explained = 0.8\n",
    "pca_s = pca.explained_variance_ratio_[np.cumsum(pca.explained_variance_ratio_) < minimum_variance_explained]\n",
    "\n",
    "embeddings = embeddings[:, range(len(pca_s))] \n",
    "\n",
    "df = pd.DataFrame(embeddings, index=data.keys(), columns=[f'pca_{num}' for num in range(embeddings.shape[1])])\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca_raw.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_41</th>\n",
       "      <th>pca_42</th>\n",
       "      <th>pca_43</th>\n",
       "      <th>pca_44</th>\n",
       "      <th>pca_45</th>\n",
       "      <th>pca_46</th>\n",
       "      <th>pca_47</th>\n",
       "      <th>pca_48</th>\n",
       "      <th>pca_49</th>\n",
       "      <th>pca_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000066</th>\n",
       "      <td>-5.446280</td>\n",
       "      <td>2.134828</td>\n",
       "      <td>-4.652717</td>\n",
       "      <td>-2.125299</td>\n",
       "      <td>0.580376</td>\n",
       "      <td>0.505437</td>\n",
       "      <td>3.645508</td>\n",
       "      <td>-1.465071</td>\n",
       "      <td>0.559960</td>\n",
       "      <td>-0.148222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353012</td>\n",
       "      <td>0.038454</td>\n",
       "      <td>0.205035</td>\n",
       "      <td>-0.641453</td>\n",
       "      <td>0.869113</td>\n",
       "      <td>0.092259</td>\n",
       "      <td>-0.582056</td>\n",
       "      <td>1.186516</td>\n",
       "      <td>-0.610516</td>\n",
       "      <td>-0.408618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000156</th>\n",
       "      <td>-8.319563</td>\n",
       "      <td>-0.242977</td>\n",
       "      <td>0.330990</td>\n",
       "      <td>2.693621</td>\n",
       "      <td>0.226985</td>\n",
       "      <td>-0.173033</td>\n",
       "      <td>0.044034</td>\n",
       "      <td>0.841468</td>\n",
       "      <td>-0.099231</td>\n",
       "      <td>-0.782438</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.260801</td>\n",
       "      <td>0.136870</td>\n",
       "      <td>0.088421</td>\n",
       "      <td>-0.792122</td>\n",
       "      <td>-0.942989</td>\n",
       "      <td>-0.917753</td>\n",
       "      <td>0.167208</td>\n",
       "      <td>-1.023388</td>\n",
       "      <td>-0.054315</td>\n",
       "      <td>0.599594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>-7.162394</td>\n",
       "      <td>-0.387870</td>\n",
       "      <td>-1.151493</td>\n",
       "      <td>1.097107</td>\n",
       "      <td>3.034690</td>\n",
       "      <td>-2.266430</td>\n",
       "      <td>-0.223179</td>\n",
       "      <td>-0.279714</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>0.161026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672399</td>\n",
       "      <td>-0.107862</td>\n",
       "      <td>0.902505</td>\n",
       "      <td>0.103369</td>\n",
       "      <td>0.715633</td>\n",
       "      <td>-0.988445</td>\n",
       "      <td>-0.291919</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>-0.161655</td>\n",
       "      <td>-0.139666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>7.118132</td>\n",
       "      <td>1.133620</td>\n",
       "      <td>1.888029</td>\n",
       "      <td>1.358146</td>\n",
       "      <td>0.974229</td>\n",
       "      <td>0.119056</td>\n",
       "      <td>2.924170</td>\n",
       "      <td>-3.068111</td>\n",
       "      <td>-3.560253</td>\n",
       "      <td>-1.671859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467257</td>\n",
       "      <td>1.129952</td>\n",
       "      <td>1.485040</td>\n",
       "      <td>-0.275029</td>\n",
       "      <td>-1.220480</td>\n",
       "      <td>-0.125073</td>\n",
       "      <td>0.981571</td>\n",
       "      <td>-0.995944</td>\n",
       "      <td>0.407328</td>\n",
       "      <td>-0.853552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000378</th>\n",
       "      <td>-3.639200</td>\n",
       "      <td>-0.193422</td>\n",
       "      <td>-4.519847</td>\n",
       "      <td>-3.138984</td>\n",
       "      <td>4.326903</td>\n",
       "      <td>-0.346467</td>\n",
       "      <td>-1.569447</td>\n",
       "      <td>-1.438142</td>\n",
       "      <td>0.437637</td>\n",
       "      <td>0.478612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138112</td>\n",
       "      <td>0.243413</td>\n",
       "      <td>0.888183</td>\n",
       "      <td>0.624756</td>\n",
       "      <td>-0.050007</td>\n",
       "      <td>-0.380207</td>\n",
       "      <td>-0.709729</td>\n",
       "      <td>1.088905</td>\n",
       "      <td>0.890469</td>\n",
       "      <td>-0.371500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823925</th>\n",
       "      <td>-4.455645</td>\n",
       "      <td>1.548255</td>\n",
       "      <td>1.318259</td>\n",
       "      <td>1.836927</td>\n",
       "      <td>-2.422237</td>\n",
       "      <td>-3.076377</td>\n",
       "      <td>1.413838</td>\n",
       "      <td>-1.080322</td>\n",
       "      <td>2.505049</td>\n",
       "      <td>-1.520907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088513</td>\n",
       "      <td>-0.649545</td>\n",
       "      <td>0.300166</td>\n",
       "      <td>-0.139134</td>\n",
       "      <td>0.258432</td>\n",
       "      <td>0.461719</td>\n",
       "      <td>-0.504943</td>\n",
       "      <td>0.859834</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>-0.095109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823932</th>\n",
       "      <td>-3.649822</td>\n",
       "      <td>2.648258</td>\n",
       "      <td>2.238149</td>\n",
       "      <td>6.375959</td>\n",
       "      <td>-3.792537</td>\n",
       "      <td>1.586219</td>\n",
       "      <td>0.554872</td>\n",
       "      <td>-1.598632</td>\n",
       "      <td>-1.841741</td>\n",
       "      <td>-1.482859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415452</td>\n",
       "      <td>0.231903</td>\n",
       "      <td>-1.232324</td>\n",
       "      <td>0.119146</td>\n",
       "      <td>0.348567</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>-0.113081</td>\n",
       "      <td>-0.491218</td>\n",
       "      <td>-0.075475</td>\n",
       "      <td>-0.585068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823981</th>\n",
       "      <td>-1.584543</td>\n",
       "      <td>1.011757</td>\n",
       "      <td>6.513752</td>\n",
       "      <td>-1.810544</td>\n",
       "      <td>1.136091</td>\n",
       "      <td>2.039510</td>\n",
       "      <td>1.944103</td>\n",
       "      <td>-1.083197</td>\n",
       "      <td>2.520791</td>\n",
       "      <td>1.933523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062662</td>\n",
       "      <td>-0.135144</td>\n",
       "      <td>0.111591</td>\n",
       "      <td>-0.342395</td>\n",
       "      <td>-0.433655</td>\n",
       "      <td>0.361703</td>\n",
       "      <td>0.123229</td>\n",
       "      <td>-0.903594</td>\n",
       "      <td>-0.113467</td>\n",
       "      <td>0.142126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824010</th>\n",
       "      <td>-5.417394</td>\n",
       "      <td>-1.422743</td>\n",
       "      <td>2.862769</td>\n",
       "      <td>1.065950</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>1.044797</td>\n",
       "      <td>1.703717</td>\n",
       "      <td>-0.196381</td>\n",
       "      <td>-2.116461</td>\n",
       "      <td>-0.533645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003317</td>\n",
       "      <td>0.531032</td>\n",
       "      <td>0.670145</td>\n",
       "      <td>-0.412963</td>\n",
       "      <td>-0.848876</td>\n",
       "      <td>-0.568218</td>\n",
       "      <td>0.165730</td>\n",
       "      <td>-0.633980</td>\n",
       "      <td>0.374417</td>\n",
       "      <td>-0.230644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824044</th>\n",
       "      <td>10.568565</td>\n",
       "      <td>-3.411498</td>\n",
       "      <td>-3.903324</td>\n",
       "      <td>6.118312</td>\n",
       "      <td>6.941116</td>\n",
       "      <td>-3.587905</td>\n",
       "      <td>0.628927</td>\n",
       "      <td>-2.270216</td>\n",
       "      <td>-1.499383</td>\n",
       "      <td>-0.767047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352854</td>\n",
       "      <td>-0.572068</td>\n",
       "      <td>0.693904</td>\n",
       "      <td>-0.257688</td>\n",
       "      <td>-0.858290</td>\n",
       "      <td>-0.701095</td>\n",
       "      <td>-0.429508</td>\n",
       "      <td>-1.081533</td>\n",
       "      <td>-2.071490</td>\n",
       "      <td>1.268018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85239 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pca_0     pca_1     pca_2     pca_3     pca_4     pca_5   \n",
       "eid                                                                    \n",
       "1000066  -5.446280  2.134828 -4.652717 -2.125299  0.580376  0.505437  \\\n",
       "1000156  -8.319563 -0.242977  0.330990  2.693621  0.226985 -0.173033   \n",
       "1000199  -7.162394 -0.387870 -1.151493  1.097107  3.034690 -2.266430   \n",
       "1000301   7.118132  1.133620  1.888029  1.358146  0.974229  0.119056   \n",
       "1000378  -3.639200 -0.193422 -4.519847 -3.138984  4.326903 -0.346467   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "3823925  -4.455645  1.548255  1.318259  1.836927 -2.422237 -3.076377   \n",
       "3823932  -3.649822  2.648258  2.238149  6.375959 -3.792537  1.586219   \n",
       "3823981  -1.584543  1.011757  6.513752 -1.810544  1.136091  2.039510   \n",
       "3824010  -5.417394 -1.422743  2.862769  1.065950  0.030327  1.044797   \n",
       "3824044  10.568565 -3.411498 -3.903324  6.118312  6.941116 -3.587905   \n",
       "\n",
       "            pca_6     pca_7     pca_8     pca_9  ...    pca_41    pca_42   \n",
       "eid                                              ...                       \n",
       "1000066  3.645508 -1.465071  0.559960 -0.148222  ...  0.353012  0.038454  \\\n",
       "1000156  0.044034  0.841468 -0.099231 -0.782438  ... -1.260801  0.136870   \n",
       "1000199 -0.223179 -0.279714 -0.669099  0.161026  ... -0.672399 -0.107862   \n",
       "1000301  2.924170 -3.068111 -3.560253 -1.671859  ...  0.467257  1.129952   \n",
       "1000378 -1.569447 -1.438142  0.437637  0.478612  ...  0.138112  0.243413   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "3823925  1.413838 -1.080322  2.505049 -1.520907  ...  0.088513 -0.649545   \n",
       "3823932  0.554872 -1.598632 -1.841741 -1.482859  ... -0.415452  0.231903   \n",
       "3823981  1.944103 -1.083197  2.520791  1.933523  ...  0.062662 -0.135144   \n",
       "3824010  1.703717 -0.196381 -2.116461 -0.533645  ... -0.003317  0.531032   \n",
       "3824044  0.628927 -2.270216 -1.499383 -0.767047  ...  1.352854 -0.572068   \n",
       "\n",
       "           pca_43    pca_44    pca_45    pca_46    pca_47    pca_48    pca_49   \n",
       "eid                                                                             \n",
       "1000066  0.205035 -0.641453  0.869113  0.092259 -0.582056  1.186516 -0.610516  \\\n",
       "1000156  0.088421 -0.792122 -0.942989 -0.917753  0.167208 -1.023388 -0.054315   \n",
       "1000199  0.902505  0.103369  0.715633 -0.988445 -0.291919  0.149660 -0.161655   \n",
       "1000301  1.485040 -0.275029 -1.220480 -0.125073  0.981571 -0.995944  0.407328   \n",
       "1000378  0.888183  0.624756 -0.050007 -0.380207 -0.709729  1.088905  0.890469   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3823925  0.300166 -0.139134  0.258432  0.461719 -0.504943  0.859834  0.008174   \n",
       "3823932 -1.232324  0.119146  0.348567  0.501581 -0.113081 -0.491218 -0.075475   \n",
       "3823981  0.111591 -0.342395 -0.433655  0.361703  0.123229 -0.903594 -0.113467   \n",
       "3824010  0.670145 -0.412963 -0.848876 -0.568218  0.165730 -0.633980  0.374417   \n",
       "3824044  0.693904 -0.257688 -0.858290 -0.701095 -0.429508 -1.081533 -2.071490   \n",
       "\n",
       "           pca_50  \n",
       "eid                \n",
       "1000066 -0.408618  \n",
       "1000156  0.599594  \n",
       "1000199 -0.139666  \n",
       "1000301 -0.853552  \n",
       "1000378 -0.371500  \n",
       "...           ...  \n",
       "3823925 -0.095109  \n",
       "3823932 -0.585068  \n",
       "3823981  0.142126  \n",
       "3824010 -0.230644  \n",
       "3824044  1.268018  \n",
       "\n",
       "[85239 rows x 51 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca_raw.parquet')\n",
    "df.index = df.index.str.split('_').str[0]\n",
    "df.index.names = ['eid']\n",
    "duplicates = df.index.duplicated(keep='first')\n",
    "df = df[~duplicates]\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df.index = df.index.str.split('_', expand=True)\n",
    "df.index.names = ['eid', 'fid', 'instance_id', 'array_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000066</th>\n",
       "      <td>-2.252839</td>\n",
       "      <td>3.066601</td>\n",
       "      <td>-2.913292</td>\n",
       "      <td>-2.328768</td>\n",
       "      <td>1.500444</td>\n",
       "      <td>1.818484</td>\n",
       "      <td>-1.092669</td>\n",
       "      <td>-1.270074</td>\n",
       "      <td>-1.512550</td>\n",
       "      <td>3.528600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000156</th>\n",
       "      <td>-5.963784</td>\n",
       "      <td>0.325908</td>\n",
       "      <td>-1.809769</td>\n",
       "      <td>2.433903</td>\n",
       "      <td>-0.624344</td>\n",
       "      <td>0.911276</td>\n",
       "      <td>-0.220119</td>\n",
       "      <td>0.139989</td>\n",
       "      <td>-0.655710</td>\n",
       "      <td>1.087488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>-4.968379</td>\n",
       "      <td>-0.170561</td>\n",
       "      <td>-0.363203</td>\n",
       "      <td>1.222055</td>\n",
       "      <td>2.232448</td>\n",
       "      <td>-0.122127</td>\n",
       "      <td>-1.113042</td>\n",
       "      <td>-0.046429</td>\n",
       "      <td>-1.952182</td>\n",
       "      <td>0.913763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>6.130622</td>\n",
       "      <td>1.322871</td>\n",
       "      <td>1.488849</td>\n",
       "      <td>-0.134390</td>\n",
       "      <td>1.098978</td>\n",
       "      <td>0.586573</td>\n",
       "      <td>-3.117746</td>\n",
       "      <td>-1.187186</td>\n",
       "      <td>0.740730</td>\n",
       "      <td>-0.114611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000378</th>\n",
       "      <td>-4.354016</td>\n",
       "      <td>-0.258280</td>\n",
       "      <td>-2.338870</td>\n",
       "      <td>-0.358884</td>\n",
       "      <td>3.314417</td>\n",
       "      <td>1.889463</td>\n",
       "      <td>-0.674396</td>\n",
       "      <td>2.056707</td>\n",
       "      <td>-1.619832</td>\n",
       "      <td>-3.547954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025959</th>\n",
       "      <td>2.996337</td>\n",
       "      <td>-0.728765</td>\n",
       "      <td>2.447221</td>\n",
       "      <td>-1.584065</td>\n",
       "      <td>-2.570893</td>\n",
       "      <td>-0.322580</td>\n",
       "      <td>-1.135632</td>\n",
       "      <td>0.223566</td>\n",
       "      <td>-0.775059</td>\n",
       "      <td>-1.589258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026028</th>\n",
       "      <td>4.927389</td>\n",
       "      <td>3.239777</td>\n",
       "      <td>0.903430</td>\n",
       "      <td>4.418314</td>\n",
       "      <td>2.202457</td>\n",
       "      <td>2.384530</td>\n",
       "      <td>1.282864</td>\n",
       "      <td>-0.437195</td>\n",
       "      <td>-0.633742</td>\n",
       "      <td>0.861229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026072</th>\n",
       "      <td>8.695135</td>\n",
       "      <td>-3.834220</td>\n",
       "      <td>-2.078501</td>\n",
       "      <td>2.316255</td>\n",
       "      <td>-0.579175</td>\n",
       "      <td>-1.012689</td>\n",
       "      <td>2.724683</td>\n",
       "      <td>0.646925</td>\n",
       "      <td>0.066713</td>\n",
       "      <td>-1.181772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026083</th>\n",
       "      <td>1.622089</td>\n",
       "      <td>0.356023</td>\n",
       "      <td>-1.366311</td>\n",
       "      <td>-1.810328</td>\n",
       "      <td>-0.948143</td>\n",
       "      <td>0.265917</td>\n",
       "      <td>0.993383</td>\n",
       "      <td>-0.537539</td>\n",
       "      <td>-0.051097</td>\n",
       "      <td>0.443448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026179</th>\n",
       "      <td>1.174178</td>\n",
       "      <td>-1.845445</td>\n",
       "      <td>-4.586893</td>\n",
       "      <td>-4.290789</td>\n",
       "      <td>2.636322</td>\n",
       "      <td>2.751485</td>\n",
       "      <td>-0.067389</td>\n",
       "      <td>0.927045</td>\n",
       "      <td>-0.518355</td>\n",
       "      <td>2.040406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86195 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pca_0     pca_1     pca_2     pca_3     pca_4     pca_5     pca_6   \n",
       "eid                                                                             \n",
       "1000066 -2.252839  3.066601 -2.913292 -2.328768  1.500444  1.818484 -1.092669  \\\n",
       "1000156 -5.963784  0.325908 -1.809769  2.433903 -0.624344  0.911276 -0.220119   \n",
       "1000199 -4.968379 -0.170561 -0.363203  1.222055  2.232448 -0.122127 -1.113042   \n",
       "1000301  6.130622  1.322871  1.488849 -0.134390  1.098978  0.586573 -3.117746   \n",
       "1000378 -4.354016 -0.258280 -2.338870 -0.358884  3.314417  1.889463 -0.674396   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "6025959  2.996337 -0.728765  2.447221 -1.584065 -2.570893 -0.322580 -1.135632   \n",
       "6026028  4.927389  3.239777  0.903430  4.418314  2.202457  2.384530  1.282864   \n",
       "6026072  8.695135 -3.834220 -2.078501  2.316255 -0.579175 -1.012689  2.724683   \n",
       "6026083  1.622089  0.356023 -1.366311 -1.810328 -0.948143  0.265917  0.993383   \n",
       "6026179  1.174178 -1.845445 -4.586893 -4.290789  2.636322  2.751485 -0.067389   \n",
       "\n",
       "            pca_7     pca_8     pca_9  \n",
       "eid                                    \n",
       "1000066 -1.270074 -1.512550  3.528600  \n",
       "1000156  0.139989 -0.655710  1.087488  \n",
       "1000199 -0.046429 -1.952182  0.913763  \n",
       "1000301 -1.187186  0.740730 -0.114611  \n",
       "1000378  2.056707 -1.619832 -3.547954  \n",
       "...           ...       ...       ...  \n",
       "6025959  0.223566 -0.775059 -1.589258  \n",
       "6026028 -0.437195 -0.633742  0.861229  \n",
       "6026072  0.646925  0.066713 -1.181772  \n",
       "6026083 -0.537539 -0.051097  0.443448  \n",
       "6026179  0.927045 -0.518355  2.040406  \n",
       "\n",
       "[86195 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collapsed = df.reset_index().groupby('eid').last()\n",
    "df_collapsed = df_collapsed.drop(['fid', 'instance_id', 'array_id'], axis=1)\n",
    "df_collapsed.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/resnet_50_pca.parquet')\n",
    "df_collapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(embeddings: torch.Tensor, labels: torch.Tensor, device) -> nn.Module:\n",
    "    # Train a linear model\n",
    "    linear_model = nn.Linear(embeddings.shape[1], len(torch.unique(labels))).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr=3e-4)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(5000):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = linear_model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return linear_model\n",
    "\n",
    "def plot_roc_curve(labels: List[int], scores: List[float]):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train a linear model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_linear_model\u001b[49m(embeddings_tensor, labels_tensor, device)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate scores using the linear model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m scores \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(linear_model(embeddings_tensor))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train a linear model\n",
    "linear_model = train_linear_model(embeddings_tensor, labels_tensor, device)\n",
    "\n",
    "# Calculate scores using the linear model\n",
    "scores = nn.functional.softmax(linear_model(embeddings_tensor)).detach().cpu().numpy()\n",
    "# Plot ROC curve for each class\n",
    "for class_label in torch.unique(labels_tensor):\n",
    "    class_scores = scores[:, class_label]\n",
    "    class_labels = [1 if label == class_label else 0 for label in labels_tensor]\n",
    "    plot_roc_curve(class_labels, class_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Evaluation - Pretrained SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pytorch_lightning/utilities/migration/migration.py:195: PossibleUserWarning: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "  rank_zero_warn(\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.0.4 to v1.9.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file https:/pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt`\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:234: UnderReviewWarning: The feature SimCLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  obj = cls(**_cls_kwargs)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/simclr/simclr_module.py:138: UnderReviewWarning: The feature resnet50 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return backbone(first_conv=self.first_conv, maxpool1=self.maxpool1, return_all_feature_maps=False)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:321: UnderReviewWarning: The feature _resnet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return _resnet(\"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:281: UnderReviewWarning: The feature ResNet is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  model = ResNet(block, layers, **kwargs)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:223: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  conv1x1(self.inplanes, planes * block.expansion, stride),\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:229: UnderReviewWarning: The feature Bottleneck is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  block(\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/resnets.py:110: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pl_bolts/models/self_supervised/simclr/simclr_module.py:126: UnderReviewWarning: The feature Projection is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.projection = Projection(input_dim=self.hidden_mlp, hidden_dim=self.hidden_mlp, output_dim=self.feat_dim)\n",
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:255: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['non_linear_evaluator.block_forward.2.weight', 'non_linear_evaluator.block_forward.2.bias']\n",
      "  rank_zero_warn(\n",
      "Process inputs: 100%|██████████| 87/87 [1:37:01<00:00, 66.92s/it]\n",
      "Process inputs: 100%|██████████| 88/88 [1:24:29<00:00, 57.61s/it]\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# model\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "model = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "model.to(device)\n",
    "model.freeze()\n",
    "\n",
    "def extract_features(model: nn.Module, dataloader: DataLoader, device: torch.device) -> np.ndarray:\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, file_names in tqdm(dataloader, desc='Process inputs'):\n",
    "            output = model(inputs.to(device))\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.extend([f.split('.')[0] for f in file_names])\n",
    "    return np.concatenate(features, axis=0).squeeze(), labels\n",
    "\n",
    "features_left, labels_left = extract_features(model, train_dataloader_left, device)\n",
    "features_right, labels_right = extract_features(model, train_dataloader_right, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/deepMMR/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "data_left = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_left, features_left)}\n",
    "data_right = {'_'.join(np.array(label.split('_'))[[0, 2, 3]]): feature for (label, feature) in zip(labels_right, features_right)}\n",
    "data = {label: np.concatenate([feature_left, data_right[label]]) for (label, feature_left) in data_left.items() if label in data_right.keys()}\n",
    "\n",
    "df = pd.DataFrame(np.stack(data.values()), index=data.keys(), columns=[f'feature_{num}' for num in range(np.stack(data.values()).shape[1])])\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_raw.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_raw.parquet')\n",
    "\n",
    "df_raw.index.names = ['eid']\n",
    "df_raw.index = df_raw.index.str.split('_').str[0]\n",
    "df_raw.index.names = ['eid']\n",
    "duplicates = df_raw.index.duplicated(keep='first')\n",
    "df_raw = df_raw[~duplicates]\n",
    "\n",
    "pca = Sklearn_PCA(n_components=256) # 10\n",
    "embeddings = pca.fit_transform(np.stack(df_raw.values))\n",
    "df = pd.DataFrame(embeddings, index=df_raw.index, columns=[f'pca_{num}' for num in range(embeddings.shape[1])])\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_pca.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000066</th>\n",
       "      <td>-1.124531</td>\n",
       "      <td>0.476144</td>\n",
       "      <td>0.039057</td>\n",
       "      <td>0.037099</td>\n",
       "      <td>0.415730</td>\n",
       "      <td>0.050869</td>\n",
       "      <td>-0.071730</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>0.515702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000156</th>\n",
       "      <td>-1.246989</td>\n",
       "      <td>-0.333761</td>\n",
       "      <td>0.595704</td>\n",
       "      <td>-0.233015</td>\n",
       "      <td>-0.303992</td>\n",
       "      <td>-0.124384</td>\n",
       "      <td>0.152929</td>\n",
       "      <td>-0.035439</td>\n",
       "      <td>0.224985</td>\n",
       "      <td>-0.022164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>-1.545924</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>0.332943</td>\n",
       "      <td>0.215149</td>\n",
       "      <td>-0.147210</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>-0.025074</td>\n",
       "      <td>-0.034308</td>\n",
       "      <td>-0.010866</td>\n",
       "      <td>-0.100134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000301</th>\n",
       "      <td>1.464271</td>\n",
       "      <td>0.471742</td>\n",
       "      <td>0.117708</td>\n",
       "      <td>-0.446180</td>\n",
       "      <td>0.069569</td>\n",
       "      <td>-0.074620</td>\n",
       "      <td>-0.111770</td>\n",
       "      <td>-0.483076</td>\n",
       "      <td>0.171306</td>\n",
       "      <td>0.125713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000378</th>\n",
       "      <td>-1.011024</td>\n",
       "      <td>-0.077450</td>\n",
       "      <td>0.054507</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>-0.424258</td>\n",
       "      <td>0.304522</td>\n",
       "      <td>-0.272214</td>\n",
       "      <td>-0.117854</td>\n",
       "      <td>0.375444</td>\n",
       "      <td>-0.005743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823925</th>\n",
       "      <td>-0.721995</td>\n",
       "      <td>-0.035558</td>\n",
       "      <td>-0.509513</td>\n",
       "      <td>-0.167597</td>\n",
       "      <td>-0.022988</td>\n",
       "      <td>-0.273178</td>\n",
       "      <td>-0.185490</td>\n",
       "      <td>0.045779</td>\n",
       "      <td>-0.054213</td>\n",
       "      <td>0.274207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823932</th>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.952701</td>\n",
       "      <td>0.346640</td>\n",
       "      <td>-0.476639</td>\n",
       "      <td>0.020480</td>\n",
       "      <td>0.344963</td>\n",
       "      <td>0.568104</td>\n",
       "      <td>-0.512069</td>\n",
       "      <td>0.072603</td>\n",
       "      <td>0.214979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823981</th>\n",
       "      <td>0.236588</td>\n",
       "      <td>0.156204</td>\n",
       "      <td>-0.349229</td>\n",
       "      <td>-0.943248</td>\n",
       "      <td>-0.027832</td>\n",
       "      <td>-0.306307</td>\n",
       "      <td>-0.173657</td>\n",
       "      <td>0.403887</td>\n",
       "      <td>-0.052307</td>\n",
       "      <td>-0.143568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824010</th>\n",
       "      <td>-0.301947</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>-0.063579</td>\n",
       "      <td>-0.485457</td>\n",
       "      <td>0.322031</td>\n",
       "      <td>-0.634809</td>\n",
       "      <td>0.067884</td>\n",
       "      <td>-0.181177</td>\n",
       "      <td>0.094405</td>\n",
       "      <td>0.288821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824044</th>\n",
       "      <td>1.846912</td>\n",
       "      <td>0.262696</td>\n",
       "      <td>1.880477</td>\n",
       "      <td>0.183165</td>\n",
       "      <td>0.186425</td>\n",
       "      <td>-0.109127</td>\n",
       "      <td>-0.732211</td>\n",
       "      <td>-0.166702</td>\n",
       "      <td>0.159945</td>\n",
       "      <td>0.431064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85239 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pca_0     pca_1     pca_2     pca_3     pca_4     pca_5     pca_6   \n",
       "eid                                                                             \n",
       "1000066 -1.124531  0.476144  0.039057  0.037099  0.415730  0.050869 -0.071730  \\\n",
       "1000156 -1.246989 -0.333761  0.595704 -0.233015 -0.303992 -0.124384  0.152929   \n",
       "1000199 -1.545924  0.019440  0.332943  0.215149 -0.147210  0.001268 -0.025074   \n",
       "1000301  1.464271  0.471742  0.117708 -0.446180  0.069569 -0.074620 -0.111770   \n",
       "1000378 -1.011024 -0.077450  0.054507  0.241299 -0.424258  0.304522 -0.272214   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3823925 -0.721995 -0.035558 -0.509513 -0.167597 -0.022988 -0.273178 -0.185490   \n",
       "3823932  0.062510  0.952701  0.346640 -0.476639  0.020480  0.344963  0.568104   \n",
       "3823981  0.236588  0.156204 -0.349229 -0.943248 -0.027832 -0.306307 -0.173657   \n",
       "3824010 -0.301947  0.019988 -0.063579 -0.485457  0.322031 -0.634809  0.067884   \n",
       "3824044  1.846912  0.262696  1.880477  0.183165  0.186425 -0.109127 -0.732211   \n",
       "\n",
       "            pca_7     pca_8     pca_9  \n",
       "eid                                    \n",
       "1000066  0.004496 -0.004564  0.515702  \n",
       "1000156 -0.035439  0.224985 -0.022164  \n",
       "1000199 -0.034308 -0.010866 -0.100134  \n",
       "1000301 -0.483076  0.171306  0.125713  \n",
       "1000378 -0.117854  0.375444 -0.005743  \n",
       "...           ...       ...       ...  \n",
       "3823925  0.045779 -0.054213  0.274207  \n",
       "3823932 -0.512069  0.072603  0.214979  \n",
       "3823981  0.403887 -0.052307 -0.143568  \n",
       "3824010 -0.181177  0.094405  0.288821  \n",
       "3824044 -0.166702  0.159945  0.431064  \n",
       "\n",
       "[85239 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_pca.parquet')\n",
    "df = df_raw.iloc[:, range(10)]\n",
    "df.to_parquet('/s/project/deepMMR/data/phenotypes/stage_1_raw/Fundus_21015_21016/sim_clr_pca_10.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-deepMMR]",
   "language": "python",
   "name": "conda-env-anaconda-deepMMR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
